{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f211031e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<img src=\"./images/logo.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d855f",
   "metadata": {},
   "source": [
    "> **Objective:**  \n",
    "> Transform unstructured data from synthetic support posts into a structured **Neo4j graph database**, enabling the discovery of relationships between user-reported **symptoms**, their **underlying root causes**, and **associated solutions**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e864e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aleynakara/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aleynakara/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aleynakara/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/Users/aleynakara/miniconda3/envs/symp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/aleynakara/miniconda3/envs/symp/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from load_data import json_to_dataframes, TEXT_COL\n",
    "from preprocess import preprocess_text\n",
    "from keyword_extraction import extract_keywords\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c13bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/aleynakara/Documents/sympTome/support_posts.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb6451",
   "metadata": {},
   "source": [
    "### üì• `load_data`: from messy JSON ‚Üí tidy DataFrame\n",
    "\n",
    "1. **File read & sanity check**  \n",
    "   `read_json_dataset(path)`  \n",
    "   * Raises `ValueError` if the file is missing, malformed, or the top-level object isn‚Äôt a list.\n",
    "\n",
    "2. **ID hygiene(Optional)**  \n",
    "   * `normalize_id()` strips alpha-prefixes (`\"post42\"` ‚Üí `42`).  \n",
    "   * `validate_ids()` rewrites duplicate / missing IDs to fresh sequential strings (`\"000\"`, `\"001\"`, ‚Ä¶).\n",
    "\n",
    "3. **Flattening logic** ‚Äì inside `json_to_dataframes(path)`  \n",
    "   | `source` flag | Row content | `comment_id` |\n",
    "   |---------------|-------------|--------------|\n",
    "   | `0` (`TITLE_CLS`) | post **title** | `NaN` |\n",
    "   | `1` (`DESCRIPTION_CLS`) | post **description** | `NaN` |\n",
    "   | `2` (`COMMENT_CLS`) | every **comment** | original comment id |\n",
    "\n",
    "   Every post can therefore produce up to three rows, all with the same `post_id`.\n",
    "\n",
    "4. **Return value**  \n",
    "   One concatenated DataFrame with columns  \n",
    "   ```text\n",
    "   post_id | comment_id | user | text | source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da25eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = json_to_dataframes(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37d9e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>comment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>post002</td>\n",
       "      <td>HomeOfficeSally</td>\n",
       "      <td>Wi-Fi signal drops frequently when I move arou...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post002</td>\n",
       "      <td>HomeOfficeSally</td>\n",
       "      <td>Whenever I go to the basement or the far end o...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post003</td>\n",
       "      <td>GamerGuy89</td>\n",
       "      <td>Ping is fine but I can't load certain websites...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>post105</td>\n",
       "      <td>TechStudentMaya</td>\n",
       "      <td>Flushing DNS and resetting fixed the connectiv...</td>\n",
       "      <td>2</td>\n",
       "      <td>c156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>post106</td>\n",
       "      <td>NetworkTech</td>\n",
       "      <td>Packet loss can be driver-related; try disabli...</td>\n",
       "      <td>2</td>\n",
       "      <td>c157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>post106</td>\n",
       "      <td>StreamerAlex</td>\n",
       "      <td>Disabling that feature stopped the packet loss...</td>\n",
       "      <td>2</td>\n",
       "      <td>c158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>post107</td>\n",
       "      <td>SupportGuy</td>\n",
       "      <td>Check if the update disabled the hosted networ...</td>\n",
       "      <td>2</td>\n",
       "      <td>c159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>post107</td>\n",
       "      <td>ITProJenna</td>\n",
       "      <td>Enabling hosted network in driver properties f...</td>\n",
       "      <td>2</td>\n",
       "      <td>c160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id              user  \\\n",
       "0    post001  TrainTravelerMax   \n",
       "1    post001  TrainTravelerMax   \n",
       "2    post002   HomeOfficeSally   \n",
       "3    post002   HomeOfficeSally   \n",
       "4    post003        GamerGuy89   \n",
       "..       ...               ...   \n",
       "323  post105   TechStudentMaya   \n",
       "324  post106       NetworkTech   \n",
       "325  post106      StreamerAlex   \n",
       "326  post107        SupportGuy   \n",
       "327  post107        ITProJenna   \n",
       "\n",
       "                                                  text  source comment_id  \n",
       "0     Struggling to log into the train service website       0        NaN  \n",
       "1    I tried accessing the train login page today b...       1        NaN  \n",
       "2    Wi-Fi signal drops frequently when I move arou...       0        NaN  \n",
       "3    Whenever I go to the basement or the far end o...       1        NaN  \n",
       "4    Ping is fine but I can't load certain websites...       0        NaN  \n",
       "..                                                 ...     ...        ...  \n",
       "323  Flushing DNS and resetting fixed the connectiv...       2       c156  \n",
       "324  Packet loss can be driver-related; try disabli...       2       c157  \n",
       "325  Disabling that feature stopped the packet loss...       2       c158  \n",
       "326  Check if the update disabled the hosted networ...       2       c159  \n",
       "327  Enabling hosted network in driver properties f...       2       c160  \n",
       "\n",
       "[328 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77af700",
   "metadata": {},
   "source": [
    "### üîß Pre-processing pipeline at a glance\n",
    "\n",
    "| Stage | What it does |\n",
    "|-------|--------------|\n",
    "| **1. Security-aware NLP core** | Loads **SecureSpacy**:<br/>‚Ä¢ swaps in its custom tokenizer<br/>‚Ä¢ inserts Trend-Micro‚Äôs EntityRuler (10 threats)<br/>This means IPs, hashes, CVEs stay intact for later steps. |\n",
    "| **2. Text sanitation helpers** | Plain regex / emoji utils:<br/>`remove_html_tag`, `replace_emojis`, `remove_urls`, `remove_punctuation_preserving_entities` |\n",
    "| **3. Entity ‚Äúbubble-wrap‚Äù** | `detect_and_preserve_entities` replaces each entity with a placeholder (`__IP_ADDRESS_0__`) so downstream cleaners never split it. After cleaning, `restore_entities` puts originals back. Also collects **keywords** (entity strings) & **labels** for later analytics. |\n",
    "| **4. Optional clean-ups** | Controlled by flags in `preprocess_text()`:<br/>`spelling_correction` ‚Üí *TextBlob*<br/>`stopword_removal` ‚Üí NLTK list<br/>`do_stemming` / `do_lemmatizing` |\n",
    "| **5. Row-wise pipeline** | `preprocess_text(df, \"text\", ‚Ä¶)`<br/>‚Üí dumps original to `text_orig` (if `suffix`) <br/>‚Üí applies steps 3‚Äì5 <br/>‚Üí returns cleaned `text`, plus new **keywords** & **labels** columns. |\n",
    "| **6. Sentence explode (optional)** | `split_into_sentences(df, \"text\")` tokenises each text into N sentences and **explodes** them into N new rows‚Äîhandy for sentence-level classification/embedding. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5840f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_stemming, do_lemmatizing = False, True\n",
    "df = preprocess_text(\n",
    "    df, TEXT_COL, do_stemming=do_stemming, do_lemmatizing=do_lemmatizing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98415ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>struggle log train service website</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>try access train login page today keep spin wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>{vpn, today}</td>\n",
       "      <td>{date, protocol}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>post002</td>\n",
       "      <td>HomeOfficeSally</td>\n",
       "      <td>wifi signal drop frequently move around house</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wi-Fi signal drops frequently when I move arou...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post002</td>\n",
       "      <td>HomeOfficeSally</td>\n",
       "      <td>whenever go basement far end live room wifi ke...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whenever I go to the basement or the far end o...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post003</td>\n",
       "      <td>GamerGuy89</td>\n",
       "      <td>ping fine cant load certain websites online game</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ping is fine but I can't load certain websites...</td>\n",
       "      <td>{ping}</td>\n",
       "      <td>{tool}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>post105</td>\n",
       "      <td>TechStudentMaya</td>\n",
       "      <td>flush dns reset fix connectivity issue</td>\n",
       "      <td>2</td>\n",
       "      <td>c156</td>\n",
       "      <td>Flushing DNS and resetting fixed the connectiv...</td>\n",
       "      <td>{dns}</td>\n",
       "      <td>{protocol}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>post106</td>\n",
       "      <td>NetworkTech</td>\n",
       "      <td>packet loss driverrelated try disable advance ...</td>\n",
       "      <td>2</td>\n",
       "      <td>c157</td>\n",
       "      <td>Packet loss can be driver-related; try disabli...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>post106</td>\n",
       "      <td>StreamerAlex</td>\n",
       "      <td>disable feature stop packet loss thank</td>\n",
       "      <td>2</td>\n",
       "      <td>c158</td>\n",
       "      <td>Disabling that feature stopped the packet loss...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>post107</td>\n",
       "      <td>SupportGuy</td>\n",
       "      <td>check update disable host network feature driver</td>\n",
       "      <td>2</td>\n",
       "      <td>c159</td>\n",
       "      <td>Check if the update disabled the hosted networ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>post107</td>\n",
       "      <td>ITProJenna</td>\n",
       "      <td>enable host network driver properties fix hotspot</td>\n",
       "      <td>2</td>\n",
       "      <td>c160</td>\n",
       "      <td>Enabling hosted network in driver properties f...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id              user  \\\n",
       "0    post001  TrainTravelerMax   \n",
       "1    post001  TrainTravelerMax   \n",
       "2    post002   HomeOfficeSally   \n",
       "3    post002   HomeOfficeSally   \n",
       "4    post003        GamerGuy89   \n",
       "..       ...               ...   \n",
       "323  post105   TechStudentMaya   \n",
       "324  post106       NetworkTech   \n",
       "325  post106      StreamerAlex   \n",
       "326  post107        SupportGuy   \n",
       "327  post107        ITProJenna   \n",
       "\n",
       "                                                  text  source comment_id  \\\n",
       "0                   struggle log train service website       0        NaN   \n",
       "1    try access train login page today keep spin wi...       1        NaN   \n",
       "2        wifi signal drop frequently move around house       0        NaN   \n",
       "3    whenever go basement far end live room wifi ke...       1        NaN   \n",
       "4     ping fine cant load certain websites online game       0        NaN   \n",
       "..                                                 ...     ...        ...   \n",
       "323             flush dns reset fix connectivity issue       2       c156   \n",
       "324  packet loss driverrelated try disable advance ...       2       c157   \n",
       "325             disable feature stop packet loss thank       2       c158   \n",
       "326   check update disable host network feature driver       2       c159   \n",
       "327  enable host network driver properties fix hotspot       2       c160   \n",
       "\n",
       "                                             text_orig      keywords  \\\n",
       "0     Struggling to log into the train service website            {}   \n",
       "1    I tried accessing the train login page today b...  {vpn, today}   \n",
       "2    Wi-Fi signal drops frequently when I move arou...            {}   \n",
       "3    Whenever I go to the basement or the far end o...            {}   \n",
       "4    Ping is fine but I can't load certain websites...        {ping}   \n",
       "..                                                 ...           ...   \n",
       "323  Flushing DNS and resetting fixed the connectiv...         {dns}   \n",
       "324  Packet loss can be driver-related; try disabli...            {}   \n",
       "325  Disabling that feature stopped the packet loss...            {}   \n",
       "326  Check if the update disabled the hosted networ...            {}   \n",
       "327  Enabling hosted network in driver properties f...            {}   \n",
       "\n",
       "               labels  \n",
       "0                  {}  \n",
       "1    {date, protocol}  \n",
       "2                  {}  \n",
       "3                  {}  \n",
       "4              {tool}  \n",
       "..                ...  \n",
       "323        {protocol}  \n",
       "324                {}  \n",
       "325                {}  \n",
       "326                {}  \n",
       "327                {}  \n",
       "\n",
       "[328 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12566897",
   "metadata": {},
   "source": [
    "### Why SecureSpacy?\n",
    "\n",
    "| Feature | SecureSpacy | spaCy |\n",
    "|---------|-------------|-------|\n",
    "| Keeps security artefacts intact (IPs, hashes, CVEs‚Ä¶) | ‚úÖ | ‚ùå |\n",
    "| Ships EntityRuler for 10 security types | ‚úÖ | ‚ùå |\n",
    "| Simple drop-in (`nlp.tokenizer = custom_tokenizer(nlp)`) | ‚úÖ | ‚Äî |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41db6733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x106bddde0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from securespacy.tokenizer import custom_tokenizer\n",
    "from securespacy.patterns import add_entity_ruler_pipeline\n",
    "\n",
    "txt = \"Ping 8.8.8.8; corp-portal[.]com still down.\"\n",
    "s_nlp = spacy.load(\"en_core_web_sm\")\n",
    "s_nlp.tokenizer = custom_tokenizer(s_nlp)\n",
    "add_entity_ruler_pipeline(s_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a711436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ping', '8.8.8.8', ';', 'corp-portal[.]com', 'still', 'down', '.']\n",
      "[('TOOL', 'Ping'), ('IP', '8.8.8.8'), ('DOMAIN', 'corp-portal[.]com')]\n"
     ]
    }
   ],
   "source": [
    "print([t.text for t in s_nlp(txt)])\n",
    "print([(e.label_, e.text) for e in s_nlp(txt).ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2269205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ping', '8.8.8.8', ';', 'corp', '-', 'portal[.]com', 'still', 'down', '.']\n",
      "[('Ping 8.8.8.8', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "d_nlp = spacy.load(\"en_core_web_sm\")\n",
    "print([t.text for t in d_nlp(txt)])\n",
    "print([(ent.text, ent.label_) for ent in d_nlp(txt).ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fbc6ea",
   "metadata": {},
   "source": [
    "### 10 entities are **not** enough! ‚Äî why we bolt on extra patterns üöÄ\n",
    "\n",
    "SecureSpacy‚Äôs built-in EntityRuler covers the classic ten artefacts (IP, URL, DOMAIN, HASH, CVE, FILE_PATH, EMAIL, REGKEY, PROCESS, VENDOR).  \n",
    "Great for malware write-ups, **but my patterns talk about a *lot* more networking stuff**.  \n",
    "So I extend the ruler with ~60 rule-based patterns (below) to catch the jargon the model ignores.\n",
    "\n",
    "| **New label** | **Example match** | **Why it matters** |\n",
    "|---------------|------------------|--------------------|\n",
    "| `IP_ADDRESS` (IPv4 & IPv6 regex) | `2001:4860:4860::8888` | IPv6 is invisible to the stock pattern |\n",
    "| `PROTOCOL` | `TCP`, `dns`, `https` | Needed for policy checks: ‚Äúis **HTTPS** open on 443?‚Äù |\n",
    "| `DEVICE` | `firewall`, `access point` | Lets the graph link tickets to assets |\n",
    "| `ERROR_MESSAGE` | `connection timed out` | Groups incidents by failure motif |\n",
    "| `NETWORK_CONCEPT` | `default gateway`, `NAT`, `SSID` | Higher-level hints for root-cause analysis |\n",
    "| `CONFIGURATION_SETTING` | `MTU`, `TTL`, `WPA2` | Surfaces the knobs mentioned in fixes |\n",
    "\n",
    "Why rules instead of retraining?\n",
    "\n",
    "1. deterministic and fast (regex/keyword)\n",
    "\n",
    "2. zero additional data labelling\n",
    "\n",
    "3. keeps annotation consistent across 10 k+ tickets\n",
    "\n",
    "4. easy to tweak when new jargon appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ae9754c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>struggle log train service website</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>try access train login page today keep spin wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>{vpn, today}</td>\n",
       "      <td>{date, protocol}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>post002</td>\n",
       "      <td>HomeOfficeSally</td>\n",
       "      <td>wifi signal drop frequently move around house</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wi-Fi signal drops frequently when I move arou...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post002</td>\n",
       "      <td>HomeOfficeSally</td>\n",
       "      <td>whenever go basement far end live room wifi ke...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whenever I go to the basement or the far end o...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post003</td>\n",
       "      <td>GamerGuy89</td>\n",
       "      <td>ping fine cant load certain websites online game</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ping is fine but I can't load certain websites...</td>\n",
       "      <td>{ping}</td>\n",
       "      <td>{tool}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>post105</td>\n",
       "      <td>TechStudentMaya</td>\n",
       "      <td>flush dns reset fix connectivity issue</td>\n",
       "      <td>2</td>\n",
       "      <td>c156</td>\n",
       "      <td>Flushing DNS and resetting fixed the connectiv...</td>\n",
       "      <td>{dns}</td>\n",
       "      <td>{protocol}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>post106</td>\n",
       "      <td>NetworkTech</td>\n",
       "      <td>packet loss driverrelated try disable advance ...</td>\n",
       "      <td>2</td>\n",
       "      <td>c157</td>\n",
       "      <td>Packet loss can be driver-related; try disabli...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>post106</td>\n",
       "      <td>StreamerAlex</td>\n",
       "      <td>disable feature stop packet loss thank</td>\n",
       "      <td>2</td>\n",
       "      <td>c158</td>\n",
       "      <td>Disabling that feature stopped the packet loss...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>post107</td>\n",
       "      <td>SupportGuy</td>\n",
       "      <td>check update disable host network feature driver</td>\n",
       "      <td>2</td>\n",
       "      <td>c159</td>\n",
       "      <td>Check if the update disabled the hosted networ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>post107</td>\n",
       "      <td>ITProJenna</td>\n",
       "      <td>enable host network driver properties fix hotspot</td>\n",
       "      <td>2</td>\n",
       "      <td>c160</td>\n",
       "      <td>Enabling hosted network in driver properties f...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id              user  \\\n",
       "0    post001  TrainTravelerMax   \n",
       "1    post001  TrainTravelerMax   \n",
       "2    post002   HomeOfficeSally   \n",
       "3    post002   HomeOfficeSally   \n",
       "4    post003        GamerGuy89   \n",
       "..       ...               ...   \n",
       "323  post105   TechStudentMaya   \n",
       "324  post106       NetworkTech   \n",
       "325  post106      StreamerAlex   \n",
       "326  post107        SupportGuy   \n",
       "327  post107        ITProJenna   \n",
       "\n",
       "                                                  text  source comment_id  \\\n",
       "0                   struggle log train service website       0        NaN   \n",
       "1    try access train login page today keep spin wi...       1        NaN   \n",
       "2        wifi signal drop frequently move around house       0        NaN   \n",
       "3    whenever go basement far end live room wifi ke...       1        NaN   \n",
       "4     ping fine cant load certain websites online game       0        NaN   \n",
       "..                                                 ...     ...        ...   \n",
       "323             flush dns reset fix connectivity issue       2       c156   \n",
       "324  packet loss driverrelated try disable advance ...       2       c157   \n",
       "325             disable feature stop packet loss thank       2       c158   \n",
       "326   check update disable host network feature driver       2       c159   \n",
       "327  enable host network driver properties fix hotspot       2       c160   \n",
       "\n",
       "                                             text_orig      keywords  \\\n",
       "0     Struggling to log into the train service website            {}   \n",
       "1    I tried accessing the train login page today b...  {vpn, today}   \n",
       "2    Wi-Fi signal drops frequently when I move arou...            {}   \n",
       "3    Whenever I go to the basement or the far end o...            {}   \n",
       "4    Ping is fine but I can't load certain websites...        {ping}   \n",
       "..                                                 ...           ...   \n",
       "323  Flushing DNS and resetting fixed the connectiv...         {dns}   \n",
       "324  Packet loss can be driver-related; try disabli...            {}   \n",
       "325  Disabling that feature stopped the packet loss...            {}   \n",
       "326  Check if the update disabled the hosted networ...            {}   \n",
       "327  Enabling hosted network in driver properties f...            {}   \n",
       "\n",
       "               labels  \n",
       "0                  {}  \n",
       "1    {date, protocol}  \n",
       "2                  {}  \n",
       "3                  {}  \n",
       "4              {tool}  \n",
       "..                ...  \n",
       "323        {protocol}  \n",
       "324                {}  \n",
       "325                {}  \n",
       "326                {}  \n",
       "327                {}  \n",
       "\n",
       "[328 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_method = \"keybert\"\n",
    "df = extract_keywords(df, TEXT_COL, method=keyword_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"text_clean\"], inplace=True)\n",
    "# df.to_csv(f\"./output/{keyword_method}_keywords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0736c5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>struggle log train train service website</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>load strangely browse access train login websi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>{today, vpn}</td>\n",
       "      <td>{protocol, date}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>post002</td>\n",
       "      <td>HomeOfficeSally</td>\n",
       "      <td>signal drop frequently</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wi-Fi signal drops frequently when I move arou...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post002</td>\n",
       "      <td>HomeOfficeSally</td>\n",
       "      <td>disconnect extremely slow wifi disconnect extr...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whenever I go to the basement or the far end o...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post003</td>\n",
       "      <td>GamerGuy89</td>\n",
       "      <td>ping fine load websites online game load certa...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ping is fine but I can't load certain websites...</td>\n",
       "      <td>{ping}</td>\n",
       "      <td>{tool}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>post105</td>\n",
       "      <td>TechStudentMaya</td>\n",
       "      <td>flush dns reset reset fix connectivity</td>\n",
       "      <td>2</td>\n",
       "      <td>c156</td>\n",
       "      <td>Flushing DNS and resetting fixed the connectiv...</td>\n",
       "      <td>{dns}</td>\n",
       "      <td>{protocol}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>post106</td>\n",
       "      <td>NetworkTech</td>\n",
       "      <td>packet loss driverrelated large send offload</td>\n",
       "      <td>2</td>\n",
       "      <td>c157</td>\n",
       "      <td>Packet loss can be driver-related; try disabli...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>post106</td>\n",
       "      <td>StreamerAlex</td>\n",
       "      <td>feature stop packet packet loss thank</td>\n",
       "      <td>2</td>\n",
       "      <td>c158</td>\n",
       "      <td>Disabling that feature stopped the packet loss...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>post107</td>\n",
       "      <td>SupportGuy</td>\n",
       "      <td>check update disable disable host network netw...</td>\n",
       "      <td>2</td>\n",
       "      <td>c159</td>\n",
       "      <td>Check if the update disabled the hosted networ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>post107</td>\n",
       "      <td>ITProJenna</td>\n",
       "      <td>properties fix hotspot network driver properti...</td>\n",
       "      <td>2</td>\n",
       "      <td>c160</td>\n",
       "      <td>Enabling hosted network in driver properties f...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id              user  \\\n",
       "0    post001  TrainTravelerMax   \n",
       "1    post001  TrainTravelerMax   \n",
       "2    post002   HomeOfficeSally   \n",
       "3    post002   HomeOfficeSally   \n",
       "4    post003        GamerGuy89   \n",
       "..       ...               ...   \n",
       "323  post105   TechStudentMaya   \n",
       "324  post106       NetworkTech   \n",
       "325  post106      StreamerAlex   \n",
       "326  post107        SupportGuy   \n",
       "327  post107        ITProJenna   \n",
       "\n",
       "                                                  text  source comment_id  \\\n",
       "0             struggle log train train service website       0        NaN   \n",
       "1    load strangely browse access train login websi...       1        NaN   \n",
       "2                               signal drop frequently       0        NaN   \n",
       "3    disconnect extremely slow wifi disconnect extr...       1        NaN   \n",
       "4    ping fine load websites online game load certa...       0        NaN   \n",
       "..                                                 ...     ...        ...   \n",
       "323             flush dns reset reset fix connectivity       2       c156   \n",
       "324       packet loss driverrelated large send offload       2       c157   \n",
       "325              feature stop packet packet loss thank       2       c158   \n",
       "326  check update disable disable host network netw...       2       c159   \n",
       "327  properties fix hotspot network driver properti...       2       c160   \n",
       "\n",
       "                                             text_orig      keywords  \\\n",
       "0     Struggling to log into the train service website            {}   \n",
       "1    I tried accessing the train login page today b...  {today, vpn}   \n",
       "2    Wi-Fi signal drops frequently when I move arou...            {}   \n",
       "3    Whenever I go to the basement or the far end o...            {}   \n",
       "4    Ping is fine but I can't load certain websites...        {ping}   \n",
       "..                                                 ...           ...   \n",
       "323  Flushing DNS and resetting fixed the connectiv...         {dns}   \n",
       "324  Packet loss can be driver-related; try disabli...            {}   \n",
       "325  Disabling that feature stopped the packet loss...            {}   \n",
       "326  Check if the update disabled the hosted networ...            {}   \n",
       "327  Enabling hosted network in driver properties f...            {}   \n",
       "\n",
       "               labels  \n",
       "0                  {}  \n",
       "1    {protocol, date}  \n",
       "2                  {}  \n",
       "3                  {}  \n",
       "4              {tool}  \n",
       "..                ...  \n",
       "323        {protocol}  \n",
       "324                {}  \n",
       "325                {}  \n",
       "326                {}  \n",
       "327                {}  \n",
       "\n",
       "[328 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc61b35",
   "metadata": {},
   "source": [
    "### üîë Keyword extraction (BERT-based default, TextRank fallback)\n",
    "\n",
    "| Step | Key parts | Why |\n",
    "|------|-----------|-----|\n",
    "| **1. Model bootstrap** | `kw_model = KeyBERT(SentenceTransformer(\"all-MiniLM-L6-v2\"))` | Uses a lightweight BERT sentence-embedder so keywords come from semantic similarity, not just TF-IDF. |\n",
    "| **2. `extract_keywords_keybert(text)`** | ‚Ä¢ Top-N phrases `kw_model.extract_keywords(...)` (1‚Äì3-grams)<br>‚Ä¢ `fuzzywuzzy.process.dedupe` drops near-duplicates (‚â• 70% match)<br>‚Ä¢ keep first **6** terms ‚Üí `\"cpu overload router\"` | Returns only the most distinctive, non-redundant nuggets. |\n",
    "| **3. DataFrame integration** | `extract_keywords(df, [\"text\"], method=\"keybert\")`<br>‚Ä¢ stores original text in `\"text_clean\"` <br>‚Ä¢ replaces `text` with space-joined keywords | Keeps the DataFrame lean: downstream models ingest only the distilled keyword string. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a324b671",
   "metadata": {},
   "source": [
    "### Why keyword extraction?\n",
    "\n",
    "* **Trim the fat** ‚Äì cut greetings & filler.  \n",
    "* **Speed** ‚Äì shorter text ‚Üí faster embeddings/search.  \n",
    "* **Focus** ‚Äì keep only high-signal phrases (symptoms, devices, configs).  \n",
    "\n",
    "KeyBERT/TextRank distil each post to ‚âà 6 sharp terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8cd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_method = \"keybert\"\n",
    "df = pd.read_csv(f\"./output/{keyword_method}_keywords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c72300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the STANFORDTOOLSDIR environment variable\n",
    "os.environ[\"STANFORDTOOLSDIR\"] = os.path.expanduser(\"~/stanford-ner-2015-12-09\")\n",
    "\n",
    "# Set the CLASSPATH to the Stanford NER jar\n",
    "os.environ[\"CLASSPATH\"] = os.path.join(\n",
    "    os.environ[\"STANFORDTOOLSDIR\"], \"stanford-ner.jar\"\n",
    ")\n",
    "\n",
    "# Set the STANFORD_MODELS to the classifiers directory\n",
    "os.environ[\"STANFORD_MODELS\"] = os.path.join(\n",
    "    os.environ[\"STANFORDTOOLSDIR\"], \"classifiers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c272b91d",
   "metadata": {},
   "source": [
    "### CRF ‚Äî Conditional Random Field (used here for NER)\n",
    "\n",
    "| What | Why it matters |\n",
    "|------|----------------|\n",
    "| **Model type** | Sequence-labeler that scores the *whole* tag chain, keeps BIO tags consistent. |\n",
    "| **Features** | Hand-crafted cues (word shape, suffix, prev-tag, etc.) feed into the CRF instead of raw embeddings. |\n",
    "| **Training / decoding** | Learns P(labels ; tokens); finds the best path with Viterbi‚Äîno GPU required. |\n",
    "\n",
    "\n",
    "*(Good on small data & resource-light but needs manual features and sees mostly local context.)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb652d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jackaduma/SecBERT were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from ner import extract_entities_from_dataframes\n",
    "\n",
    "ner_method = \"stanford\"\n",
    "df = extract_entities_from_dataframes(df, method=ner_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f\"./output/{ner_method}_entities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_method = \"stanford\"\n",
    "df = pd.read_csv(f\"./output/{ner_method}_entities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371f00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>source</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>struggle log train train service website</td>\n",
       "      <td>{'train', 'website', 'service', 'struggle', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>{'protocol', 'date'}</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>load strangely browse access train login websi...</td>\n",
       "      <td>{'train', 'access', 'fine', 'login', 'websites...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>post002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Wi-Fi signal drops frequently when I move arou...</td>\n",
       "      <td>signal drop frequently</td>\n",
       "      <td>{'signal', 'drop', 'frequently'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>set()</td>\n",
       "      <td>Whenever I go to the basement or the far end o...</td>\n",
       "      <td>disconnect extremely slow wifi disconnect extr...</td>\n",
       "      <td>{'slow', 'wifi', 'disconnect', 'extremely', 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'tool'}</td>\n",
       "      <td>Ping is fine but I can't load certain websites...</td>\n",
       "      <td>ping fine load websites online game load certa...</td>\n",
       "      <td>{'fine', 'websites', 'online', 'game', 'certai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>post105</td>\n",
       "      <td>c156</td>\n",
       "      <td>2</td>\n",
       "      <td>{'protocol'}</td>\n",
       "      <td>Flushing DNS and resetting fixed the connectiv...</td>\n",
       "      <td>flush dns reset reset fix connectivity</td>\n",
       "      <td>{'connectivity', 'reset', 'dns', 'fix', 'flush'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>post106</td>\n",
       "      <td>c157</td>\n",
       "      <td>2</td>\n",
       "      <td>set()</td>\n",
       "      <td>Packet loss can be driver-related; try disabli...</td>\n",
       "      <td>packet loss driverrelated large send offload</td>\n",
       "      <td>{'packet', 'offload', 'loss', 'large', 'driver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>post106</td>\n",
       "      <td>c158</td>\n",
       "      <td>2</td>\n",
       "      <td>set()</td>\n",
       "      <td>Disabling that feature stopped the packet loss...</td>\n",
       "      <td>feature stop packet packet loss thank</td>\n",
       "      <td>{'packet', 'feature', 'stop', 'thank', 'loss'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>post107</td>\n",
       "      <td>c159</td>\n",
       "      <td>2</td>\n",
       "      <td>set()</td>\n",
       "      <td>Check if the update disabled the hosted networ...</td>\n",
       "      <td>check update disable disable host network netw...</td>\n",
       "      <td>{'network', 'feature', 'disable', 'update', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>post107</td>\n",
       "      <td>c160</td>\n",
       "      <td>2</td>\n",
       "      <td>set()</td>\n",
       "      <td>Enabling hosted network in driver properties f...</td>\n",
       "      <td>properties fix hotspot network driver properti...</td>\n",
       "      <td>{'network', 'hotspot', 'enable', 'properties',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id comment_id  source                labels  \\\n",
       "0    post001        NaN       0                 set()   \n",
       "1    post001        NaN       1  {'protocol', 'date'}   \n",
       "2    post002        NaN       0                 set()   \n",
       "3    post002        NaN       1                 set()   \n",
       "4    post003        NaN       0              {'tool'}   \n",
       "..       ...        ...     ...                   ...   \n",
       "323  post105       c156       2          {'protocol'}   \n",
       "324  post106       c157       2                 set()   \n",
       "325  post106       c158       2                 set()   \n",
       "326  post107       c159       2                 set()   \n",
       "327  post107       c160       2                 set()   \n",
       "\n",
       "                                             text_orig  \\\n",
       "0     Struggling to log into the train service website   \n",
       "1    I tried accessing the train login page today b...   \n",
       "2    Wi-Fi signal drops frequently when I move arou...   \n",
       "3    Whenever I go to the basement or the far end o...   \n",
       "4    Ping is fine but I can't load certain websites...   \n",
       "..                                                 ...   \n",
       "323  Flushing DNS and resetting fixed the connectiv...   \n",
       "324  Packet loss can be driver-related; try disabli...   \n",
       "325  Disabling that feature stopped the packet loss...   \n",
       "326  Check if the update disabled the hosted networ...   \n",
       "327  Enabling hosted network in driver properties f...   \n",
       "\n",
       "                                                  text  \\\n",
       "0             struggle log train train service website   \n",
       "1    load strangely browse access train login websi...   \n",
       "2                               signal drop frequently   \n",
       "3    disconnect extremely slow wifi disconnect extr...   \n",
       "4    ping fine load websites online game load certa...   \n",
       "..                                                 ...   \n",
       "323             flush dns reset reset fix connectivity   \n",
       "324       packet loss driverrelated large send offload   \n",
       "325              feature stop packet packet loss thank   \n",
       "326  check update disable disable host network netw...   \n",
       "327  properties fix hotspot network driver properti...   \n",
       "\n",
       "                                              keywords  \n",
       "0    {'train', 'website', 'service', 'struggle', 'l...  \n",
       "1    {'train', 'access', 'fine', 'login', 'websites...  \n",
       "2                     {'signal', 'drop', 'frequently'}  \n",
       "3    {'slow', 'wifi', 'disconnect', 'extremely', 'r...  \n",
       "4    {'fine', 'websites', 'online', 'game', 'certai...  \n",
       "..                                                 ...  \n",
       "323   {'connectivity', 'reset', 'dns', 'fix', 'flush'}  \n",
       "324  {'packet', 'offload', 'loss', 'large', 'driver...  \n",
       "325     {'packet', 'feature', 'stop', 'thank', 'loss'}  \n",
       "326  {'network', 'feature', 'disable', 'update', 'd...  \n",
       "327  {'network', 'hotspot', 'enable', 'properties',...  \n",
       "\n",
       "[328 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_classification import classify_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86ddd25",
   "metadata": {},
   "source": [
    "### OpenAI splitter ‚Äî why it‚Äôs handy\n",
    "\n",
    "* **Graph-ready nodes** ‚Äì GPT tags each chunk as **symptom (0) / cause (1) / solution (2)** ‚Üí direct import to Neo4j.\n",
    "* **Auto-segment** ‚Äì breaks mixed sentences (‚ÄúWi-Fi drops; rebooting fixes it‚Äù) into separate rows, no regex pain.\n",
    "* **Context-aware** ‚Äì prompt feeds in our keywords & NER labels ‚Üí sharper, domain-specific decisions.\n",
    "* **Zero retraining** ‚Äì tweak the prompt, not a model; great for fast iteration.\n",
    "* **Clean output** ‚Äì `classify_text(df)` explodes the DataFrame with new `segment` and `node_type` columns, ready for the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4915f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying and splitting rows:   0%|          | 0/328 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text \"struggle log train train service website\" doesn't provide clear context or information about a specific network troubleshooting issue. Therefore, it's not possible to generate a JSON array with node_type and text keys. More context or a more detailed description of the issue would be needed to perform this task.'\n",
      "Classifying and splitting rows:   1%|          | 2/328 [00:04<12:25,  2.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to accurately classify the text snippet into symptoms, causes, or solutions. The text snippet \"load strangely browse access train login websites fine vpn\" does not provide clear context or structure to determine if it's describing a problem (symptom), the reason for the problem (cause), or how to fix the problem (solution). \n",
      "\n",
      "The keywords and labels provided also do not provide additional context as they are just individual characters and not meaningful words or phrases. \n",
      "\n",
      "In order to provide a meaningful classification, more context or a more structured text snippet would be needed. For example, a text snippet like \"The webpage loads strangely when I try to access it through the VPN\" would provide a clear symptom that can be classified. \n",
      "\n",
      "Without additional context or information, it's not possible to provide the requested JSON array of objects.'\n",
      "Classifying and splitting rows:   1%|          | 3/328 [00:11<23:10,  4.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:   1%|          | 4/328 [00:13<17:32,  3.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:   2%|‚ñè         | 5/328 [00:16<18:18,  3.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:   2%|‚ñè         | 6/328 [00:21<20:59,  3.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to be a symptom description. However, it's not clear enough to identify a cause or a solution. Therefore, the JSON object would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"ping game servers servers low stable\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:   2%|‚ñè         | 7/328 [00:25<20:42,  3.87s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"connect wifi internet\", it's not clear whether this is a symptom, a cause, or a solution. However, it's most likely a solution or a task that a user is trying to perform. Therefore, the JSON object would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"connect wifi internet\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that without more context, it's difficult to accurately classify the text snippet.'\n",
      "Classifying and splitting rows:   2%|‚ñè         | 8/328 [00:30<23:08,  4.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:   3%|‚ñé         | 9/328 [00:33<19:41,  3.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"desk wifi barely\", it seems to be describing a symptom of a problem. There is no cause or solution mentioned in the snippet. Therefore, the JSON array would contain only one object, representing the symptom.\n",
      "\n",
      "Here is the JSON array:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"desk wifi barely\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:   3%|‚ñé         | 10/328 [00:36<19:35,  3.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:   3%|‚ñé         | 11/328 [00:38<16:41,  3.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to perform the task. The text snippet \"access work ethernet\" does not clearly indicate whether it is a symptom, a cause, or a solution. Additionally, the keywords and labels provided do not provide any additional context. Please provide more detailed information.'\n",
      "Classifying and splitting rows:   4%|‚ñé         | 12/328 [00:41<16:05,  3.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:   4%|‚ñç         | 13/328 [00:44<16:02,  3.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to perform the task. The text snippet \"disconnect randomly video\" is not clear enough to identify distinct parts and classify them as a symptom, a cause, or a solution. The keywords and labels provided also do not provide any additional context or information. Please provide more detailed or clear information.'\n",
      "Classifying and splitting rows:   4%|‚ñç         | 14/328 [00:49<18:07,  3.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to classify the text snippet into symptom, cause, or solution. The text snippet \"conferences vpn connection\" is too vague and does not provide enough context to determine whether it is describing a symptom, a cause, or a solution. Additionally, the provided keywords and labels do not provide any additional information that could be used to classify the text snippet. More context or a more detailed text snippet would be needed to accurately classify the information.'\n",
      "Classifying and splitting rows:   5%|‚ñç         | 15/328 [00:53<19:40,  3.77s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"slow internet laptop\", it seems to be describing a symptom rather than a cause or a solution. Therefore, the JSON object would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"slow internet laptop\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This is because the text snippet is describing a problem (slow internet on a laptop), which is a symptom of a potential network issue. There is no mention of a cause or a solution in the text snippet.'\n",
      "Classifying and splitting rows:   5%|‚ñç         | 16/328 [00:59<22:20,  4.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts as symptoms, causes, or solutions due to the lack of context and sentence structure. However, an attempt can be made to interpret the given text:\n",
      "\n",
      "1. \"devices network fast\" - This could be interpreted as a symptom where the devices are experiencing a fast network.\n",
      "2. \"fast laptop crawl network\" - This could be interpreted as a symptom where a fast laptop is experiencing slow network speeds.\n",
      "3. \"fast laptop\" - This could be interpreted as a solution where the recommendation is to use a fast laptop.\n",
      "\n",
      "Here is the JSON array of these objects:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"devices network fast\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"fast laptop crawl network\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"fast laptop\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is highly subjective and may not be accurate due to the lack of context and sentence structure in the provided text snippet.'\n",
      "Classifying and splitting rows:   5%|‚ñå         | 17/328 [01:08<29:34,  5.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:   5%|‚ñå         | 18/328 [01:10<24:37,  4.77s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:   6%|‚ñå         | 19/328 [01:13<20:48,  4.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"company intranet accessible\", it is difficult to classify it into distinct parts such as symptom, cause, or solution as it is a single statement. However, it can be interpreted as a symptom if the context is that the company intranet should not be accessible or as a solution if the context is that the company intranet was previously inaccessible. Without additional context, it's not possible to accurately classify this snippet. \n",
      "\n",
      "Assuming it's a symptom, the output would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"company intranet accessible\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Assuming it's a solution, the output would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"company intranet accessible\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please provide more context or a more complex text snippet for a more accurate classification.'\n",
      "Classifying and splitting rows:   6%|‚ñå         | 20/328 [01:20<26:42,  5.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's not clear how to divide it into distinct parts related to symptoms, causes, or solutions. The text \"company intranet page remotely rest internet\" seems to be a single statement without clear indication of a problem (symptom), its cause, or a solution. \n",
      "\n",
      "However, if we interpret this text as a symptom (i.e., the user is unable to access the company intranet page remotely but the rest of the internet is accessible), the output would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"company intranet page remotely rest internet\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please provide more context or a more detailed text snippet for a more accurate classification.'\n",
      "Classifying and splitting rows:   6%|‚ñã         | 21/328 [01:27<28:07,  5.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems there is only one distinct part which is a symptom. The symptom is that the university websites are loading slowly. However, there is no cause or solution provided in the text snippet. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"load university websites slow\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that the keywords and labels extracted do not seem to match the text snippet and may need to be reviewed.'\n",
      "Classifying and splitting rows:   7%|‚ñã         | 22/328 [01:31<26:07,  5.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information seems to be incorrect or incomplete. The text snippet \"university sit load really slow sit\" doesn't seem to make much sense and the keywords extracted are individual characters rather than meaningful words or phrases. The labels assigned also seem to be individual characters rather than meaningful labels. \n",
      "\n",
      "Given the information provided, it's not possible to accurately identify and classify distinct parts of the text snippet as symptoms, causes, or solutions. \n",
      "\n",
      "Please provide a valid text snippet, keywords, and labels for accurate classification.'\n",
      "Classifying and splitting rows:   7%|‚ñã         | 23/328 [01:37<26:51,  5.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:   7%|‚ñã         | 24/328 [01:39<22:14,  4.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's not possible to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text \"cloud storage time file cloud storage\" doesn't provide enough context to make a clear classification. \n",
      "\n",
      "However, if we were to make an assumption, we could interpret the text as a symptom of a problem related to cloud storage. Here's how we could represent this in JSON:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"cloud storage time file cloud storage\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is based on an assumption due to lack of context. In a real-world scenario, we would need more information to make accurate classifications.'\n",
      "Classifying and splitting rows:   8%|‚ñä         | 25/328 [01:46<26:40,  5.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to perform the task. The text snippet \"video conference audio conference audio wifi access video conference\" does not clearly indicate any symptoms, causes, or solutions related to network troubleshooting. The keywords and labels provided also do not provide any additional context or information that could be used to classify parts of the text snippet. \n",
      "\n",
      "In order to perform this task, more context or a more detailed text snippet would be needed. For example, a text snippet like \"The video conference was interrupted due to poor wifi access\" could be broken down into a symptom (\"The video conference was interrupted\") and a cause (\"poor wifi access\"). \n",
      "\n",
      "Similarly, the keywords and labels provided do not seem to be related to the text snippet or to network troubleshooting. They appear to be individual characters rather than meaningful words or phrases. \n",
      "\n",
      "In conclusion, without additional information or context, it is not possible to perform the requested task.'\n",
      "Classifying and splitting rows:   8%|‚ñä         | 26/328 [01:54<30:49,  6.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet and the extracted keywords, it's not possible to accurately classify the text into symptoms, causes, or solutions. The text snippet \"drop distort connect distort connect wifi audio drop distort\" seems to describe a series of issues or symptoms related to network connectivity and audio quality, but without more context or a clearer understanding of the problem, it's difficult to identify causes or solutions. \n",
      "\n",
      "The keywords extracted don't provide additional information that could help in this classification. They are simply individual characters from the text snippet, not meaningful words or phrases.\n",
      "\n",
      "The labels assigned also don't provide useful information for this task. They are individual characters, not labels that could help identify parts of the text as symptoms, causes, or solutions.\n",
      "\n",
      "Given these limitations, the best we can do is classify the entire text snippet as a symptom, since it seems to describe a problem. Here is the JSON object for this classification:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"drop distort connect distort connect wifi audio drop distort\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Please note that this classification is based on limited information and may not be accurate.'\n",
      "Classifying and splitting rows:   8%|‚ñä         | 27/328 [02:02<33:48,  6.74s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"desk wifi barely\", it seems to be describing a symptom of a problem. There is no cause or solution mentioned in the snippet. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"desk wifi barely\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This indicates that the text \"desk wifi barely\" is identified as a symptom (node_type: 0).'\n",
      "Classifying and splitting rows:   9%|‚ñä         | 28/328 [02:08<31:36,  6.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"relocate desk suddenly suddenly wifi speed\" seems to be incomplete and lacks context. However, an attempt can be made to interpret it as follows:\n",
      "\n",
      "1. \"relocate desk\" - This could be interpreted as a solution to a problem. The action of relocating the desk might be suggested as a way to improve wifi speed.\n",
      "2. \"suddenly suddenly wifi speed\" - This could be interpreted as a symptom. The sudden change in wifi speed is the issue that needs to be addressed.\n",
      "\n",
      "Here is the JSON array of these objects:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"relocate desk\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"suddenly suddenly wifi speed\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation might not be accurate due to the lack of context and the incomplete nature of the text snippet.'\n",
      "Classifying and splitting rows:   9%|‚ñâ         | 29/328 [02:17<35:20,  7.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:   9%|‚ñâ         | 30/328 [02:18<27:04,  5.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:   9%|‚ñâ         | 31/328 [02:20<21:53,  4.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  10%|‚ñâ         | 32/328 [02:22<18:11,  3.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"router restart day people log\" seems to be incomplete and lacks context. However, if we assume that the text is about a router that needs to be restarted every day for people to log in, we could interpret it as follows:\n",
      "\n",
      "- \"router restart day\" could be seen as a symptom, indicating that the router needs to be restarted daily.\n",
      "- \"people log\" could be seen as a solution, suggesting that people can log in after the router is restarted.\n",
      "\n",
      "Here is the JSON array of these objects:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"router restart day\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"people log\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is based on assumptions and may not be accurate. For a more accurate classification, a more complete and clear text snippet would be helpful.'\n",
      "Classifying and splitting rows:  10%|‚ñà         | 33/328 [02:30<24:41,  5.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  10%|‚ñà         | 34/328 [02:32<19:24,  3.96s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  11%|‚ñà         | 35/328 [02:34<16:17,  3.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"open sit campus sit campus wifi\" seems to be a statement or command rather than a troubleshooting scenario. \n",
      "\n",
      "However, if we interpret \"open sit campus sit campus wifi\" as a user trying to connect to the campus wifi, it could be classified as a symptom (i.e., the user is unable to connect to the campus wifi). \n",
      "\n",
      "Here is a possible JSON array:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"open sit campus sit campus wifi\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this case, \"node_type\": 0 indicates that the text is a symptom. The \"text\" is the exact substring from the original snippet corresponding to that part. \n",
      "\n",
      "Please note that this interpretation might not be accurate due to the lack of context and clear troubleshooting elements in the provided text snippet.'\n",
      "Classifying and splitting rows:  11%|‚ñà         | 36/328 [02:41<22:13,  4.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  11%|‚ñà‚ñè        | 37/328 [02:44<19:55,  4.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"stream use repeater\", it's not clear whether it's a symptom, a cause, or a solution. The text is too brief and lacks context. However, assuming that the text is suggesting to use a repeater to improve the stream, it can be considered as a solution. Here is the JSON object:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"stream use repeater\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  12%|‚ñà‚ñè        | 38/328 [02:48<19:36,  4.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  12%|‚ñà‚ñè        | 39/328 [02:51<17:37,  3.66s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to be describing a symptom rather than a cause or a solution. However, without more context, it's difficult to accurately classify the snippet. Here's a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"file share coworkers connect file share\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, the text snippet is considered a symptom (node_type: 0) because it describes a situation where coworkers are trying to connect to a file share, which could be a problem if they're unable to do so. However, without more information, it's impossible to determine if this is a cause of a problem or a solution to one.'\n",
      "Classifying and splitting rows:  12%|‚ñà‚ñè        | 40/328 [02:56<19:58,  4.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  12%|‚ñà‚ñé        | 41/328 [03:00<18:46,  3.93s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"access work ethernet\", it's not clear if it's a symptom, a cause, or a solution. The text is too vague and lacks context to accurately classify it into one of the categories. Therefore, it's not possible to return a JSON array of objects with \"node_type\" and \"text\" keys. More information or a more detailed text snippet would be needed to perform this task.'\n",
      "Classifying and splitting rows:  13%|‚ñà‚ñé        | 42/328 [03:04<18:43,  3.93s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  13%|‚ñà‚ñé        | 43/328 [03:06<16:13,  3.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to be describing a symptom of a network issue. However, without more context, it's difficult to identify a cause or solution. Here's the JSON object for the symptom:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"high latency packet latency packet loss packet loss online\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this is a preliminary classification. For a more accurate classification, more context or a more detailed description of the problem would be helpful.'\n",
      "Classifying and splitting rows:  13%|‚ñà‚ñé        | 44/328 [03:11<18:24,  3.89s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  14%|‚ñà‚ñé        | 45/328 [03:13<15:31,  3.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to classify the text snippet into symptom, cause, or solution. The text snippet \"corporate email sync email sync mobile\" seems to be a symptom or a task but without further context, it's not possible to accurately classify it. The keywords extracted and labels assigned do not provide any additional information for classification. Please provide more context or detailed information.'\n",
      "Classifying and splitting rows:  14%|‚ñà‚ñç        | 46/328 [03:16<15:23,  3.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  14%|‚ñà‚ñç        | 47/328 [03:18<13:36,  2.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet \"wifi drop microwave\", it seems like there is a symptom and a cause mentioned. The symptom is \"wifi drop\" and the cause is \"microwave\". Microwaves are known to cause interference with wifi signals, leading to drops. However, there is no solution mentioned in the text snippet. \n",
      "\n",
      "Here is the JSON array of these objects:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"wifi drop\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"microwave\"\n",
      "  }\n",
      "]'\n",
      "Classifying and splitting rows:  15%|‚ñà‚ñç        | 48/328 [03:22<15:31,  3.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"speed drop disconnect microwave wifi speed\" seems to be a list of keywords related to network troubleshooting rather than a coherent sentence or phrase. \n",
      "\n",
      "However, if we interpret \"speed drop disconnect\" as a symptom and \"microwave wifi speed\" as a cause, the output could be as follows:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"speed drop disconnect\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"microwave wifi speed\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is based on assumptions and may not be accurate. For a more accurate classification, it would be helpful to have more context or a more detailed text snippet.'\n",
      "Classifying and splitting rows:  15%|‚ñà‚ñç        | 49/328 [03:30<21:43,  4.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  15%|‚ñà‚ñå        | 50/328 [03:33<19:14,  4.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  16%|‚ñà‚ñå        | 51/328 [03:35<16:39,  3.61s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"print network printer\", it's difficult to identify distinct parts that could be classified as a symptom, a cause, or a solution. The phrase seems to be a command or an action rather than a description of a problem (symptom), its cause, or a solution to it. \n",
      "\n",
      "However, if we interpret \"print network printer\" as a symptom (i.e., the user is unable to print to a network printer), the output would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"print network printer\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation might not be accurate without additional context.'\n",
      "Classifying and splitting rows:  16%|‚ñà‚ñå        | 52/328 [03:41<19:49,  4.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's not clear if it's describing a symptom, a cause, or a solution as it's quite brief and lacks context. However, it seems to be describing a situation or a process, so it could be interpreted as a symptom. Here's a possible classification:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"laptop network printer connect ethernet\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this is a very basic interpretation. For a more accurate classification, more context or a more detailed description would be helpful.'\n",
      "Classifying and splitting rows:  16%|‚ñà‚ñå        | 53/328 [03:47<21:56,  4.79s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  16%|‚ñà‚ñã        | 54/328 [03:51<20:07,  4.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems there is only one distinct part which is a symptom. The text \"portal doesnt load doesnt load sit\" indicates a problem or issue, which is typically classified as a symptom in troubleshooting context. However, without more context, it's hard to identify a cause or solution. Here is the JSON object:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"portal doesnt load doesnt load sit\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  17%|‚ñà‚ñã        | 55/328 [03:55<20:21,  4.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  17%|‚ñà‚ñã        | 56/328 [03:57<16:55,  3.73s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"bulbs cameras wifi smart bulbs cameras cameras wifi slow\" seems to be a list of devices or components related to a network, but it doesn't provide clear context about a specific problem (symptom), its cause, or a solution. \n",
      "\n",
      "However, the word \"slow\" could potentially be interpreted as a symptom related to the \"wifi\". In this case, the output could be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"wifi slow\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is based on assumptions and may not accurately represent the intended meaning of the original text snippet. For more accurate classification, it would be helpful to have more context or a more detailed description of the network issue.'\n",
      "Classifying and splitting rows:  17%|‚ñà‚ñã        | 57/328 [04:05<22:45,  5.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  18%|‚ñà‚ñä        | 58/328 [04:08<18:45,  4.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  18%|‚ñà‚ñä        | 59/328 [04:11<16:59,  3.79s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided information, it's not possible to accurately classify the text snippet \"signal strong video\" into distinct parts such as symptom, cause, or solution. The text snippet is too vague and lacks context. Therefore, it's not possible to generate the requested JSON array of objects. More detailed information or a more specific text snippet would be needed to perform this task.'\n",
      "Classifying and splitting rows:  18%|‚ñà‚ñä        | 60/328 [04:14<16:40,  3.73s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's not possible to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"conferences freeze audio bar video conferences video conferences freeze\" seems to describe a symptom (conferences freezing) but doesn't provide information about a cause or a solution. \n",
      "\n",
      "However, if we were to assume that the freezing of the conferences is the symptom, the output would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"conferences freeze audio bar video conferences video conferences freeze\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this is an assumption and the actual classification may vary based on the complete context of the text snippet.'\n",
      "Classifying and splitting rows:  19%|‚ñà‚ñä        | 61/328 [04:21<21:06,  4.75s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  19%|‚ñà‚ñâ        | 62/328 [04:25<19:04,  4.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  19%|‚ñà‚ñâ        | 63/328 [04:27<16:12,  3.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  20%|‚ñà‚ñâ        | 64/328 [04:29<13:49,  3.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to perform the task. The keywords and labels extracted do not provide any meaningful information about the text snippet. The text snippet \"network service spike ping spike online\" seems to describe a symptom (network service and ping spikes), but without further context, it's impossible to identify a cause or solution. \n",
      "\n",
      "Based on the available information, the output would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"network service spike ping spike online\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please provide more detailed and context-rich information for a more accurate classification.'\n",
      "Classifying and splitting rows:  20%|‚ñà‚ñâ        | 65/328 [04:34<16:29,  3.76s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  20%|‚ñà‚ñà        | 66/328 [04:37<15:47,  3.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  20%|‚ñà‚ñà        | 67/328 [04:39<14:07,  3.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  21%|‚ñà‚ñà        | 68/328 [04:42<13:31,  3.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The given text snippet \"speedtest 20mbps upload\" seems to be a symptom description, indicating the result of a network speed test. It does not provide any information about a cause or a solution. Therefore, the JSON object would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"speedtest 20mbps upload\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  21%|‚ñà‚ñà        | 69/328 [04:45<13:33,  3.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to perform the task. The text snippet \"pc work phone specific website windows\" does not clearly indicate a symptom, cause, or solution for a network troubleshooting issue. The keywords extracted do not provide additional context, and the labels assigned do not seem to be related to network troubleshooting. More context or a more detailed text snippet would be needed to perform this task.'\n",
      "Classifying and splitting rows:  21%|‚ñà‚ñà‚ñè       | 70/328 [04:49<13:34,  3.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"windows desktop err_connection_timed_out\", it appears to be a symptom of a problem. There is no cause or solution mentioned in the text. Therefore, the JSON array would be:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"windows desktop err_connection_timed_out\"\n",
      "  }\n",
      "]'\n",
      "Classifying and splitting rows:  22%|‚ñà‚ñà‚ñè       | 71/328 [04:52<13:28,  3.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"multiple network profile network profile cause\", it seems to be describing a cause. However, without more context, it's difficult to accurately classify the parts. Here's a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"multiple network profile network profile cause\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, the entire text snippet is classified as a cause (node_type: 1). The text \"multiple network profile network profile cause\" could be indicating that having multiple network profiles is the cause of a network issue.'\n",
      "Classifying and splitting rows:  22%|‚ñà‚ñà‚ñè       | 72/328 [04:57<16:19,  3.83s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to describe a symptom rather than a cause or a solution. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"network network adapter apps wont connect\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This is because the text snippet describes a problem or issue (i.e., apps not being able to connect due to a network adapter issue), which is typically classified as a symptom in troubleshooting contexts.'\n",
      "Classifying and splitting rows:  22%|‚ñà‚ñà‚ñè       | 73/328 [05:02<17:17,  4.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"settings reset reboot\", it seems like it's a solution to a problem. However, without more context, it's hard to accurately classify each part. Here's a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"settings reset reboot\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, \"settings reset reboot\" is considered a solution (node_type: 2) to a potential network troubleshooting issue.'\n",
      "Classifying and splitting rows:  23%|‚ñà‚ñà‚ñé       | 74/328 [05:06<17:14,  4.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  23%|‚ñà‚ñà‚ñé       | 75/328 [05:09<16:13,  3.85s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"say internet secure connect say internet\" is ambiguous and lacks clear context. However, if we were to make an assumption, it could be interpreted as a symptom of a problem where the internet is not securely connecting. \n",
      "\n",
      "Here is a possible JSON array output:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"say internet secure connect say internet\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this case, \"node_type\": 0 indicates that the text is classified as a symptom. The \"text\" is the exact substring from the original snippet. \n",
      "\n",
      "Please note that this interpretation is based on assumptions due to the lack of clear context in the provided text snippet.'\n",
      "Classifying and splitting rows:  23%|‚ñà‚ñà‚ñé       | 76/328 [05:16<20:06,  4.79s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  23%|‚ñà‚ñà‚ñé       | 77/328 [05:19<17:13,  4.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to be describing a symptom rather than a cause or a solution. However, without more context, it's difficult to accurately classify the snippet. Here's a possible classification:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"google drive sync sync work windows\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This classification assumes that the text snippet is describing a symptom where Google Drive sync is not working on Windows. If more context was provided, it might be possible to identify a cause or solution within the text.'\n",
      "Classifying and splitting rows:  24%|‚ñà‚ñà‚ñç       | 78/328 [05:23<17:41,  4.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  24%|‚ñà‚ñà‚ñç       | 79/328 [05:26<15:10,  3.66s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it seems to describe a symptom rather than a cause or a solution. However, without more context, it's difficult to accurately classify the snippet. Here's a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"network adapter disappear adapter disappear sleep disappear sleep mode\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, the text snippet is treated as a single symptom: the network adapter disappearing after the computer goes into sleep mode.'\n",
      "Classifying and splitting rows:  24%|‚ñà‚ñà‚ñç       | 80/328 [05:31<17:24,  4.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  25%|‚ñà‚ñà‚ñç       | 81/328 [05:33<14:55,  3.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  25%|‚ñà‚ñà‚ñå       | 82/328 [05:36<13:18,  3.24s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  25%|‚ñà‚ñà‚ñå       | 83/328 [05:39<13:01,  3.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  26%|‚ñà‚ñà‚ñå       | 84/328 [05:41<12:20,  3.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts as symptoms, causes, or solutions. The text snippet seems to be a series of keywords related to network troubleshooting, but they don't form coherent sentences or phrases that can be classified into symptoms, causes, or solutions. \n",
      "\n",
      "However, if we were to make assumptions, we could interpret \"vpn status connect connect\" as a symptom, \"access dev internal tool\" as a cause, and \"internet\" as a solution. \n",
      "\n",
      "Here is the JSON array based on these assumptions:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"vpn status connect connect\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"access dev internal tool\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"internet\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is highly subjective and may not be accurate. For a more accurate classification, it would be helpful to have more context or more detailed and coherent text snippets.'\n",
      "Classifying and splitting rows:  26%|‚ñà‚ñà‚ñå       | 85/328 [05:49<18:02,  4.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"signal drop room\", it seems to be describing a symptom of a network issue. There is no cause or solution mentioned in the snippet. Therefore, the JSON array would contain only one object representing the symptom.\n",
      "\n",
      "Here is the JSON array:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"signal drop room\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that the node_type 0 represents a symptom. The text \"signal drop room\" is a description of the symptom.'\n",
      "Classifying and splitting rows:  26%|‚ñà‚ñà‚ñå       | 86/328 [05:53<17:10,  4.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  27%|‚ñà‚ñà‚ñã       | 87/328 [05:55<14:53,  3.71s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  27%|‚ñà‚ñà‚ñã       | 88/328 [05:57<12:36,  3.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information seems to be incorrect. The keywords and labels extracted are not valid. They are just individual characters and not meaningful words or phrases. Also, the text snippet \"ping websites like service time load\" does not clearly indicate a symptom, cause, or solution. It seems like a command or an action. \n",
      "\n",
      "Please provide a valid text snippet, keywords, and labels for proper classification.'\n",
      "Classifying and splitting rows:  27%|‚ñà‚ñà‚ñã       | 89/328 [06:00<12:30,  3.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"connect internet game\", it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. However, assuming that the text snippet is a symptom where a user is unable to connect to the internet for a game, the output would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"connect internet game\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that without more context or a more detailed text snippet, it's challenging to accurately classify the text into symptom, cause, or solution.'\n",
      "Classifying and splitting rows:  27%|‚ñà‚ñà‚ñã       | 90/328 [06:06<14:53,  3.75s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  28%|‚ñà‚ñà‚ñä       | 91/328 [06:08<13:47,  3.49s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'As an AI model, I'm unable to process real-time data. However, I can provide a hypothetical example based on the given scenario. \n",
      "\n",
      "In this case, the text snippet \"disconnect video meetings\" is quite brief and doesn't provide clear context to classify it into symptom, cause, or solution. However, assuming this phrase is a symptom experienced by a user, the output would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"disconnect video meetings\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "If more context was provided, such as \"I keep getting disconnected from video meetings because of unstable internet connection\", we could classify it as follows:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"disconnect video meetings\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"unstable internet connection\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this case, \"disconnect video meetings\" is identified as a symptom (node_type: 0) and \"unstable internet connection\" is identified as a cause (node_type: 1).'\n",
      "Classifying and splitting rows:  28%|‚ñà‚ñà‚ñä       | 92/328 [06:19<21:54,  5.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  28%|‚ñà‚ñà‚ñä       | 93/328 [06:21<17:45,  4.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  29%|‚ñà‚ñà‚ñä       | 94/328 [06:23<15:02,  3.86s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  29%|‚ñà‚ñà‚ñâ       | 95/328 [06:25<12:38,  3.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to perform the task. The text snippet \"router work internet\" is too vague and does not clearly indicate a symptom, cause, or solution. The keywords and labels provided also do not provide any additional context. Please provide more detailed information.'\n",
      "Classifying and splitting rows:  29%|‚ñà‚ñà‚ñâ       | 96/328 [06:28<11:53,  3.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's not clear to separate it into distinct parts such as symptom, cause, or solution. However, the text seems to be more related to a symptom or a problem. Here is a possible classification:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"routers ip address load websites service\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that without more context or a more detailed text snippet, it's challenging to accurately classify the text into symptom, cause, or solution.'\n",
      "Classifying and splitting rows:  30%|‚ñà‚ñà‚ñâ       | 97/328 [06:33<14:19,  3.72s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, there is only one distinct part identified which is a symptom. The symptom is \"slow internet hours\". There is no cause or solution provided in the text snippet. Therefore, the JSON array will contain only one object.\n",
      "\n",
      "Here is the JSON array:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"slow internet hours\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  30%|‚ñà‚ñà‚ñâ       | 98/328 [06:37<14:24,  3.76s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems there is only one distinct part which is a symptom. The text \"internet speed tank speed tank pm\" seems to describe a problem or symptom of a network issue, specifically a drop in internet speed. However, there is no clear cause or solution provided in the text snippet. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"internet speed tank speed tank pm\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that the interpretation of the text snippet could vary based on the context in which it is used.'\n",
      "Classifying and splitting rows:  30%|‚ñà‚ñà‚ñà       | 99/328 [06:43<16:30,  4.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"signal bar file file wont download\" seems to be a symptom description, but without more context, it's hard to be certain. \n",
      "\n",
      "Here is a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"signal bar file file wont download\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, the entire text snippet is treated as a symptom (node_type: 0) because it describes a problem that the user is experiencing. However, without more context or a clearer description, it's not possible to identify a cause or a solution.'\n",
      "Classifying and splitting rows:  30%|‚ñà‚ñà‚ñà       | 100/328 [06:49<18:59,  5.00s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  31%|‚ñà‚ñà‚ñà       | 101/328 [06:51<15:40,  4.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  31%|‚ñà‚ñà‚ñà       | 102/328 [06:54<13:41,  3.64s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  31%|‚ñà‚ñà‚ñà‚ñè      | 103/328 [06:56<12:39,  3.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  32%|‚ñà‚ñà‚ñà‚ñè      | 104/328 [06:58<11:00,  2.95s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  32%|‚ñà‚ñà‚ñà‚ñè      | 105/328 [07:01<10:36,  2.86s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  32%|‚ñà‚ñà‚ñà‚ñè      | 106/328 [07:03<09:45,  2.64s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  33%|‚ñà‚ñà‚ñà‚ñé      | 107/328 [07:05<09:17,  2.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"disconnect laptop sleep\", it seems to be a symptom description. However, without more context, it's hard to definitively classify it. Here's the JSON object for this interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"disconnect laptop sleep\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  33%|‚ñà‚ñà‚ñà‚ñé      | 108/328 [07:10<11:07,  3.03s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it seems to describe a symptom of a network issue. However, without more context, it's difficult to accurately classify each part as a symptom, cause, or solution. Here's a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"sleep vpn disconnect\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"reconnect automatically wake\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, both parts are classified as symptoms (node_type: 0) because they describe behaviors of the VPN - disconnecting during sleep and reconnecting upon wake. However, this is a tentative classification and could change with more context.'\n",
      "Classifying and splitting rows:  33%|‚ñà‚ñà‚ñà‚ñé      | 109/328 [07:16<14:41,  4.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"connect stream videos\", it's not clear if it's a symptom, a cause, or a solution. However, it seems to be a symptom where a user is having trouble connecting to stream videos. Therefore, the JSON object would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"connect stream videos\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that without more context, it's challenging to accurately classify the text snippet.'\n",
      "Classifying and splitting rows:  34%|‚ñà‚ñà‚ñà‚ñé      | 110/328 [07:21<15:09,  4.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems there is only one part which is a symptom. The user is having trouble connecting to YouTube and Netflix videos over WiFi. There is no cause or solution provided in the text. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"youtube netflix videos connect wifi youtube\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  34%|‚ñà‚ñà‚ñà‚ñç      | 111/328 [07:24<14:36,  4.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  34%|‚ñà‚ñà‚ñà‚ñç      | 112/328 [07:27<13:13,  3.67s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  34%|‚ñà‚ñà‚ñà‚ñç      | 113/328 [07:29<11:14,  3.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"frequently disconnect windows\", it seems to be describing a symptom of a problem. There is no cause or solution mentioned in the snippet. Therefore, the JSON object would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"frequently disconnect windows\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This indicates that the text \"frequently disconnect windows\" is a symptom (node_type: 0) of a network problem.'\n",
      "Classifying and splitting rows:  35%|‚ñà‚ñà‚ñà‚ñç      | 114/328 [07:33<12:09,  3.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems there is only one distinct part which is a symptom. The symptom is that the wifi on a Windows laptop is disconnecting randomly. There is no cause or solution provided in the text snippet. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"disconnect wifi randomly windows laptop disconnect\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  35%|‚ñà‚ñà‚ñà‚ñå      | 115/328 [07:37<12:30,  3.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  35%|‚ñà‚ñà‚ñà‚ñå      | 116/328 [07:38<10:23,  2.94s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it seems to describe a symptom rather than a cause or a solution. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"hotel wifi allow phone laptop simultaneously\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This is because the text snippet describes a situation (a hotel's wifi allowing both a phone and a laptop to connect simultaneously), which is a symptom of a potential network issue, rather than a cause of an issue or a solution to an issue.'\n",
      "Classifying and splitting rows:  36%|‚ñà‚ñà‚ñà‚ñå      | 117/328 [07:42<11:33,  3.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  36%|‚ñà‚ñà‚ñà‚ñå      | 118/328 [07:44<10:04,  2.88s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to perform the task. The text snippet \"transfer vpn longer\" does not clearly indicate whether it is a symptom, a cause, or a solution. Additionally, the keywords and labels extracted do not provide any additional context. Please provide more detailed information.'\n",
      "Classifying and splitting rows:  36%|‚ñà‚ñà‚ñà‚ñã      | 119/328 [07:48<10:35,  3.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"connect ip address\", it's not clear whether this is a symptom, a cause, or a solution. However, in the context of network troubleshooting, this phrase is often used as a solution or a step to resolve network issues. Therefore, the output would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"connect ip address\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that without more context, it's challenging to accurately classify the text snippet.'\n",
      "Classifying and splitting rows:  37%|‚ñà‚ñà‚ñà‚ñã      | 120/328 [07:53<12:26,  3.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet seems to be a sequence of keywords related to network troubleshooting, but it doesn't form a coherent sentence or phrase that could be classified. \n",
      "\n",
      "However, if we were to make assumptions based on the given keywords, we could potentially interpret the text snippet as follows:\n",
      "\n",
      "- \"device connect wifi\": This could be a symptom, indicating that a device is trying to connect to wifi.\n",
      "- \"wifi ip address\": This could be a cause, suggesting that there might be an issue with the wifi IP address.\n",
      "- \"address access internet\": This could be a solution, implying that accessing the internet requires addressing the IP.\n",
      "\n",
      "Here's how these parts could be represented as JSON objects:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"device connect wifi\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"wifi ip address\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"address access internet\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is based on assumptions and might not accurately represent the original intent of the text snippet.'\n",
      "Classifying and splitting rows:  37%|‚ñà‚ñà‚ñà‚ñã      | 121/328 [08:05<21:22,  6.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  37%|‚ñà‚ñà‚ñà‚ñã      | 122/328 [08:09<18:57,  5.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'As an AI model, I can't process real-time data. However, based on the given text snippet \"hotel wifi initially\", it seems like it's a part of a symptom description. Here's how you might structure the JSON object:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"hotel wifi initially\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this is a hypothetical output. The actual output would depend on the complete context of the text snippet.'\n",
      "Classifying and splitting rows:  38%|‚ñà‚ñà‚ñà‚ñä      | 123/328 [08:14<18:20,  5.37s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  38%|‚ñà‚ñà‚ñà‚ñä      | 124/328 [08:17<15:42,  4.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts as symptoms, causes, or solutions. However, a possible interpretation could be:\n",
      "\n",
      "- \"vpn game detect location\" could be seen as a symptom, as it describes a situation where a VPN is being used for a game and it's detecting the location.\n",
      "- \"block play\" could be seen as a solution, as it suggests blocking the play as a way to address the issue.\n",
      "\n",
      "Here is the JSON array of these objects:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"vpn game detect location\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"block play\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is based on the limited context provided and may not accurately reflect the intended meaning of the text snippet.'\n",
      "Classifying and splitting rows:  38%|‚ñà‚ñà‚ñà‚ñä      | 125/328 [08:25<18:45,  5.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"connect slow devices\", it seems to be describing a symptom of a network issue. Therefore, the classification would be as follows:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"connect slow devices\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This JSON object indicates that the text \"connect slow devices\" is identified as a symptom (node_type: 0) in the context of network troubleshooting.'\n",
      "Classifying and splitting rows:  38%|‚ñà‚ñà‚ñà‚ñä      | 126/328 [08:29<17:37,  5.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  39%|‚ñà‚ñà‚ñà‚ñä      | 127/328 [08:32<14:49,  4.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text \"drop connection video vpn drop connection\" seems to describe a symptom of a problem, but without further context, it's not possible to identify a cause or solution. \n",
      "\n",
      "Here is a possible output based on the given information:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"drop connection video vpn drop connection\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This output suggests that the entire text snippet is a symptom (node_type: 0) of a network problem. However, without additional context or information, it's not possible to provide a more detailed or accurate classification.'\n",
      "Classifying and splitting rows:  39%|‚ñà‚ñà‚ñà‚ñâ      | 128/328 [08:39<18:07,  5.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"video frequently drop frequently drop freeze\", it seems to describe a symptom of a network issue. However, without more context, it's not possible to identify a cause or solution from this snippet. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"video frequently drop frequently drop freeze\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This indicates that the text snippet is a symptom of a network issue.'\n",
      "Classifying and splitting rows:  39%|‚ñà‚ñà‚ñà‚ñâ      | 129/328 [08:45<18:06,  5.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  40%|‚ñà‚ñà‚ñà‚ñâ      | 130/328 [08:48<15:31,  4.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"bar stream videos stream videos buffer wifi bar stream\" seems to be a jumbled collection of words related to streaming videos and wifi, but it doesn't clearly describe a symptom, cause, or solution to a network troubleshooting issue.\n",
      "\n",
      "However, if we interpret \"stream videos buffer\" as a symptom (videos buffering while streaming), and \"wifi bar stream\" as a cause (weak wifi signal causing the buffering), the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"stream videos buffer\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"wifi bar stream\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is based on assumptions and may not accurately represent the original intent of the text snippet. For more accurate results, it would be helpful to have more context or a more structured text snippet.'\n",
      "Classifying and splitting rows:  40%|‚ñà‚ñà‚ñà‚ñâ      | 131/328 [08:57<20:00,  6.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  40%|‚ñà‚ñà‚ñà‚ñà      | 132/328 [08:59<16:14,  4.97s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information seems to be incorrect. The keywords and labels extracted do not seem to be relevant to the text snippet provided. The text snippet \"connect access internal vpn connect access\" seems to be a command or an action rather than a symptom, cause, or solution. \n",
      "\n",
      "However, if we were to analyze the text snippet, it could be interpreted as a solution to a problem. The problem could be \"unable to access internal resources\" and the solution provided in the text snippet is \"connect access internal vpn connect access\". \n",
      "\n",
      "Here is a possible output based on this interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"connect access internal vpn connect access\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please provide more accurate data for a more accurate analysis and classification.'\n",
      "Classifying and splitting rows:  41%|‚ñà‚ñà‚ñà‚ñà      | 133/328 [09:07<18:33,  5.71s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  41%|‚ñà‚ñà‚ñà‚ñà      | 134/328 [09:09<15:14,  4.71s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  41%|‚ñà‚ñà‚ñà‚ñà      | 135/328 [09:12<13:26,  4.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 136/328 [09:15<12:05,  3.78s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to describe a solution to a network problem. However, without more context, it's difficult to accurately classify the text. Here's a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"disconnect short time force reconnect\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, \"disconnect short time force reconnect\" is seen as a solution (node_type: 2) to a potential network issue.'\n",
      "Classifying and splitting rows:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 137/328 [09:19<12:35,  3.96s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 138/328 [09:22<11:21,  3.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 139/328 [09:24<09:41,  3.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"disconnect phone sleep\", it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. However, a possible interpretation could be:\n",
      "\n",
      "1. \"disconnect phone\" - This could be interpreted as a solution, suggesting that the user should disconnect their phone.\n",
      "2. \"sleep\" - This could be interpreted as a symptom, suggesting that the device is going into sleep mode.\n",
      "\n",
      "Here is the JSON array of these objects:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"disconnect phone\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"sleep\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is based on the limited context provided and may not be accurate.'\n",
      "Classifying and splitting rows:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 140/328 [09:33<14:57,  4.77s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet seems to be a list of keywords related to network troubleshooting rather than a coherent sentence or paragraph. However, an attempt can be made to interpret the given text snippet:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"connection sleep interrupt\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"interrupt download stream\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"phone lose wifi\"\n",
      "  }\n",
      "]\n",
      "\n",
      "In this interpretation, each phrase is considered as a separate symptom (node_type: 0) related to network troubleshooting. However, without more context or a more structured text snippet, it's challenging to accurately classify the text into symptoms, causes, or solutions.'\n",
      "Classifying and splitting rows:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 141/328 [09:40<16:51,  5.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 142/328 [09:42<14:14,  4.60s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 143/328 [09:46<13:18,  4.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 144/328 [09:49<11:39,  3.80s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts as symptoms, causes, or solutions. The text snippet \"wifi signal strength websites apps forever\" seems to be a symptom description, but it's not clear enough to provide a definite classification. \n",
      "\n",
      "However, if we assume that the text snippet is describing a symptom where the wifi signal strength is affecting the loading time of websites and apps, the output could be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"wifi signal strength websites apps forever\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this is a tentative classification based on the assumption. The text snippet lacks clear context and information to accurately classify it into symptom, cause, or solution.'\n",
      "Classifying and splitting rows:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 145/328 [09:55<14:19,  4.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 146/328 [09:58<12:03,  3.98s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 147/328 [10:02<11:54,  3.95s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to describe a symptom rather than a cause or a solution. Therefore, the JSON object would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"connection slow unstable unstable work hours\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This is because the text snippet describes a problem (a slow and unstable connection during work hours), which is a symptom of a potential network issue. There is no mention of a cause or a solution in the text snippet.'\n",
      "Classifying and splitting rows:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 148/328 [10:06<12:10,  4.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 149/328 [10:08<10:13,  3.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 150/328 [10:10<08:37,  2.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 151/328 [10:12<08:34,  2.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it seems to be describing a symptom rather than a cause or a solution. The text does not provide any information about why the issue is happening (cause) or how to resolve it (solution). Therefore, the JSON object would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"company vpn connect access internal email\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This indicates that the issue (symptom) is with the company's VPN connection for accessing internal emails.'\n",
      "Classifying and splitting rows:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 152/328 [10:18<11:02,  3.77s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 153/328 [10:21<10:03,  3.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to only contain a symptom description. There is no clear cause or solution mentioned. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"strong slow internet signal strong slow\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This indicates that the text snippet is identified as a symptom (node_type: 0) and the exact substring from the original snippet is \"strong slow internet signal strong slow\".'\n",
      "Classifying and splitting rows:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 154/328 [10:26<11:20,  3.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 155/328 [10:28<09:51,  3.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to perform the task. The text snippet \"disconnect frequently cod\" does not clearly indicate whether it is a symptom, a cause, or a solution. Also, the keywords and labels extracted do not provide any additional context. Please provide more detailed information.'\n",
      "Classifying and splitting rows:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 156/328 [10:32<09:45,  3.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 157/328 [10:34<08:51,  3.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's not possible to accurately classify the parts into symptom, cause, or solution as the snippet \"cause high ping ping spike despite\" is not a complete sentence and lacks context. However, if we were to make an assumption, it could be interpreted as a symptom (\"high ping ping spike\"). \n",
      "\n",
      "In this case, the output would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"high ping ping spike\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation might not be accurate due to the lack of context.'\n",
      "Classifying and splitting rows:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 158/328 [10:40<11:04,  3.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to describe a symptom rather than a cause or a solution. However, without more context, it's difficult to accurately classify the snippet. Here's a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"sudden spike lag ping average low\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, the text \"sudden spike lag ping average low\" is classified as a symptom (node_type: 0) as it seems to describe a sudden increase in lag and a low average ping, which are issues often encountered in network troubleshooting.'\n",
      "Classifying and splitting rows:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 159/328 [10:46<12:35,  4.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"disconnect laptop sleep\", it seems to be describing a symptom where the laptop disconnects when it goes to sleep. However, without more context, it's difficult to identify a cause or solution. Therefore, the JSON array would only contain one object representing the symptom:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"disconnect laptop sleep\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 160/328 [10:50<12:30,  4.47s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 161/328 [10:53<10:50,  3.89s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts that could be classified as a symptom, a cause, or a solution. The text \"wifi log repeatedly hotel wifi log\" seems to be a repetition of the same phrase, which could be interpreted as a symptom of a problem (repeated logging into hotel wifi). However, without more context, it's not possible to identify a cause or solution. \n",
      "\n",
      "Here is a possible output based on this interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"wifi log repeatedly hotel wifi log\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation might not be accurate due to the lack of context and the repetition in the text snippet.'\n",
      "Classifying and splitting rows:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 162/328 [11:00<13:55,  5.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"wifi log multiple kick hotel wifi\" seems to be a symptom description of a problem where the wifi at a hotel is repeatedly disconnecting (kicking off) users. However, without more context, it's challenging to identify a cause or solution. \n",
      "\n",
      "Here is a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"wifi log multiple kick hotel wifi\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, the entire text snippet is treated as a symptom (node_type: 0). The text does not provide enough information to identify a cause or solution.'\n",
      "Classifying and splitting rows:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 163/328 [11:07<15:03,  5.48s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 164/328 [11:09<12:17,  4.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it seems to only contain a symptom. There is no cause or solution mentioned in the text. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"speed drop drastically hours affect productivity\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This indicates that the symptom is a drastic drop in speed over hours, which is affecting productivity.'\n",
      "Classifying and splitting rows:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 165/328 [11:13<11:58,  4.41s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 166/328 [11:17<11:05,  4.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is insufficient to perform the task. The text snippet \"signal webpages apps\" does not clearly indicate whether it is a symptom, a cause, or a solution. Additionally, the keywords and labels provided do not provide any additional context. More detailed information or a more descriptive text snippet is required to accurately perform the task.'\n",
      "Classifying and splitting rows:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 167/328 [11:20<10:33,  3.93s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 168/328 [11:23<09:34,  3.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information seems to be incorrect. The keywords and labels extracted do not seem to be relevant to the text snippet provided. The text snippet \"access foreign stream vpn access foreign\" seems to be related to a network troubleshooting issue, possibly related to accessing a foreign stream via a VPN. However, the keywords and labels provided do not provide any meaningful information related to this. \n",
      "\n",
      "Please provide the correct keywords and labels for the text snippet so that it can be properly classified into symptom, cause, or solution.'\n",
      "Classifying and splitting rows:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 169/328 [11:27<09:57,  3.76s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 170/328 [11:29<08:45,  3.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 171/328 [11:32<08:02,  3.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 172/328 [11:34<07:21,  2.83s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 173/328 [11:37<07:16,  2.81s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 174/328 [11:40<07:34,  2.95s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it seems to be describing a symptom rather than a cause or a solution. The text does not provide any information about what might be causing the issue or how to solve it. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"adapter driver ping ping spike randomly\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This indicates that the text \"adapter driver ping ping spike randomly\" is identified as a symptom (node_type: 0).'\n",
      "Classifying and splitting rows:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 175/328 [11:46<09:25,  3.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 176/328 [11:48<08:19,  3.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 177/328 [11:51<07:49,  3.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 178/328 [11:53<07:29,  2.99s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 179/328 [11:55<06:47,  2.73s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"prevent auto reconnect driver update prevent\" seems to be a solution or a recommendation rather than a symptom or a cause. However, without more context, it's challenging to provide a more accurate classification. Here is a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"prevent auto reconnect driver update prevent\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, the entire text snippet is considered as a solution (node_type: 2) to a potential problem. However, this is a tentative classification and might change with more context or information.'\n",
      "Classifying and splitting rows:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 180/328 [12:03<10:17,  4.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 181/328 [12:06<09:03,  3.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 182/328 [12:09<08:24,  3.46s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 183/328 [12:12<08:28,  3.50s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 184/328 [12:18<10:24,  4.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 185/328 [12:20<08:40,  3.64s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 186/328 [12:24<08:20,  3.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts that could be classified as a symptom, a cause, or a solution. The text snippet \"driver experience packet adapter driver experience network adapter driver\" seems to be a repetition of terms related to network drivers, but it doesn't provide a clear context or description of a problem (symptom), its cause, or a solution. \n",
      "\n",
      "Therefore, without additional context or information, it's not possible to provide a JSON array of objects classifying parts of the text as symptoms, causes, or solutions.'\n",
      "Classifying and splitting rows:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 187/328 [12:29<09:30,  4.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 188/328 [12:31<08:12,  3.52s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 189/328 [12:34<07:44,  3.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 190/328 [12:52<17:39,  7.68s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"cache cookies cause browser cache cookies\", it seems to be describing a cause. However, the text is not very clear and might be missing some context. Based on the given information, here is the JSON array:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"cache cookies cause browser cache cookies\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that the classification might not be accurate due to the lack of context and clarity in the text snippet.'\n",
      "Classifying and splitting rows:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 191/328 [12:56<15:02,  6.59s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 192/328 [12:59<12:26,  5.49s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 193/328 [13:01<10:20,  4.60s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 194/328 [13:03<08:07,  3.64s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts as symptoms, causes, or solutions. The text \"filter router block address filter router\" seems to be a command or a solution to a problem rather than a symptom or a cause. However, without more context, it's challenging to provide a more accurate classification. \n",
      "\n",
      "Here is a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"filter router block address filter router\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, the entire text snippet is considered a solution (node_type: 2) as it seems to be a command or action to be taken on a network device.'\n",
      "Classifying and splitting rows:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 195/328 [13:10<10:17,  4.64s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 196/328 [13:12<08:35,  3.90s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"interference nearby devices\", it seems to be describing a symptom of a network issue. Therefore, the classification would be as follows:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"interference nearby devices\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This JSON object indicates that the text \"interference nearby devices\" is identified as a symptom (node_type: 0) in the context of network troubleshooting.'\n",
      "Classifying and splitting rows:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 197/328 [13:16<08:54,  4.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems that there is only one part present which is a solution. The text \"router dhcp settings dhcp settings possible\" suggests a possible solution to a network issue. However, without more context, it's hard to definitively classify this snippet. Here is the JSON object:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"router dhcp settings dhcp settings possible\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 198/328 [13:21<08:51,  4.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 199/328 [13:24<08:26,  3.93s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 200/328 [13:27<07:33,  3.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 201/328 [13:29<06:45,  3.19s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 202/328 [13:33<07:07,  3.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 203/328 [13:35<06:21,  3.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"outage dns server\", it seems to be describing a symptom of a network issue. Therefore, the JSON object would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"outage dns server\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This is because the text snippet is describing a problem (an outage of a DNS server), which is a symptom of a network issue. There is no cause or solution mentioned in the text snippet.'\n",
      "Classifying and splitting rows:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 204/328 [13:40<07:36,  3.68s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 205/328 [13:43<06:40,  3.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the text snippet provided, it seems to describe a symptom rather than a cause or a solution. However, without more context, it's difficult to accurately classify each part. Here's a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"congestion\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"dns resolution issue\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"specific domains\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, each part of the text snippet is considered a separate symptom. \"Congestion\" could refer to network congestion, \"dns resolution issue\" could refer to problems with Domain Name System resolution, and \"specific domains\" could refer to the specific domains that are experiencing these issues.'\n",
      "Classifying and splitting rows:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 206/328 [13:50<09:13,  4.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 207/328 [13:53<07:57,  3.95s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 208/328 [13:55<06:52,  3.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 209/328 [13:58<06:18,  3.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"interference nearby devices\", it seems to be describing a symptom of a network issue. However, without additional context, it's challenging to identify distinct parts and classify them as a symptom, a cause, or a solution. \n",
      "\n",
      "Here is the JSON object for the given text snippet:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"interference nearby devices\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this case, \"node_type\": 0 indicates that the text is identified as a symptom.'\n",
      "Classifying and splitting rows:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 210/328 [14:04<07:56,  4.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 211/328 [14:06<06:50,  3.51s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 212/328 [14:09<06:26,  3.33s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 213/328 [14:11<05:57,  3.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 214/328 [14:15<05:58,  3.14s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts as symptoms, causes, or solutions. However, an attempt can be made to interpret the text as follows:\n",
      "\n",
      "1. \"repeaters halve bandwidth\" - This could be interpreted as a symptom where the use of repeaters is causing the bandwidth to be halved.\n",
      "2. \"upgrade mesh wifi\" - This could be interpreted as a solution where upgrading the mesh wifi is suggested to resolve the issue.\n",
      "\n",
      "The JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"repeaters halve bandwidth\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"upgrade mesh wifi\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is based on the assumption that the text snippet is related to network troubleshooting. The actual classification may vary based on the complete context of the text.'\n",
      "Classifying and splitting rows:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 215/328 [14:23<08:53,  4.72s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 216/328 [14:26<07:36,  4.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to be a description of a possible solution or setting to be checked in network troubleshooting. However, without more context, it's hard to definitively classify it. Here's a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"router dhcp settings\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"dhcp settings possible\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, both \"router dhcp settings\" and \"dhcp settings possible\" are considered as potential solutions or settings to be checked in the process of network troubleshooting.'\n",
      "Classifying and splitting rows:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 217/328 [14:33<09:04,  4.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to be a solution or a recommendation rather than a symptom or a cause. However, without more context, it's difficult to accurately classify the text. Here's a possible classification:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"wifi isolation enable guest wifi isolation routers guest wifi\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this case, \"node_type\": 2 represents a solution. The text \"wifi isolation enable guest wifi isolation routers guest wifi\" seems to be a recommendation or a solution to a potential network issue.'\n",
      "Classifying and splitting rows:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 218/328 [14:38<09:18,  5.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"interference overload network network use wire\" seems to be a mix of terms related to network troubleshooting, but it doesn't form a coherent sentence or phrase that can be easily classified.\n",
      "\n",
      "However, if we were to make an assumption, we could interpret \"interference overload network\" as a symptom and \"network use wire\" as a potential solution. Here's how that could look in JSON format:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"interference overload network\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"network use wire\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is highly speculative due to the lack of context and sentence structure in the provided text snippet.'\n",
      "Classifying and splitting rows:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 219/328 [14:46<10:41,  5.88s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"require vpn remote\", it's not clear whether it's a symptom, a cause, or a solution. However, it seems like a requirement or a solution to a problem. Therefore, the JSON object would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"require vpn remote\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that without more context, it's challenging to accurately classify the text snippet.'\n",
      "Classifying and splitting rows:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 220/328 [14:50<09:49,  5.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 221/328 [14:53<08:28,  4.75s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 222/328 [14:57<07:51,  4.45s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts as symptoms, causes, or solutions. The text \"prevent printer discovery isolation different subnets\" seems to be a solution or a task to be performed rather than a symptom or a cause. However, without more context, it's challenging to provide a more accurate classification. Here is a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"prevent printer discovery isolation different subnets\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 223/328 [15:02<08:05,  4.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 224/328 [15:06<07:28,  4.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems to be describing a symptom rather than a cause or a solution. However, without more context, it's difficult to accurately classify the snippet. Here's a possible classification:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"saturate network bandwidth devices saturate network\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This classification assumes that the text snippet is describing a symptom where devices are saturating the network bandwidth.'\n",
      "Classifying and splitting rows:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 225/328 [15:10<07:37,  4.44s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 226/328 [15:13<06:32,  3.85s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 227/328 [15:17<06:31,  3.87s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 228/328 [15:20<06:13,  3.73s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"check realtek driver\", it seems to be a solution to a potential problem. However, without additional context, it's difficult to identify a symptom or cause. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"check realtek driver\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This indicates that the text \"check realtek driver\" is a solution (node_type: 2) to a potential network troubleshooting issue.'\n",
      "Classifying and splitting rows:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 229/328 [15:25<06:31,  3.95s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 230/328 [15:28<06:14,  3.82s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 231/328 [15:31<05:50,  3.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 232/328 [15:35<05:50,  3.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided text snippet does not seem to contain any clear symptom, cause, or solution related to network troubleshooting. It appears to be a registry path in a Windows operating system, which might be relevant in a troubleshooting context, but without additional context, it's not possible to classify it as a symptom, cause, or solution. Therefore, no JSON objects can be generated based on the provided information.'\n",
      "Classifying and splitting rows:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 233/328 [15:39<05:43,  3.61s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 234/328 [15:41<05:10,  3.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 235/328 [15:44<04:43,  3.05s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 236/328 [15:45<04:01,  2.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet and the extracted keywords, it's challenging to accurately classify the parts into symptom, cause, or solution due to the lack of context and the nature of the keywords. However, based on the common issues in network troubleshooting, we can make an educated guess.\n",
      "\n",
      "Here is a possible classification:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"bug sleep power settings\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"bug drivers\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"settings drivers\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this classification:\n",
      "- \"bug sleep power settings\" is classified as a symptom (node_type: 0). It could refer to a problem where the computer goes to sleep and disrupts the network settings.\n",
      "- \"bug drivers\" is classified as a cause (node_type: 1). It could refer to faulty or outdated drivers causing the issue.\n",
      "- \"settings drivers\" is classified as a solution (node_type: 2). It could refer to the action of setting or updating the drivers to fix the issue.\n",
      "\n",
      "Please note that this is a hypothetical classification and might not accurately represent the actual parts due to the lack of context.'\n",
      "Classifying and splitting rows:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 237/328 [15:56<07:37,  5.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 238/328 [16:00<07:09,  4.78s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it seems to be a solution or a procedure to follow for network troubleshooting. However, without more context, it's hard to definitively classify each part. Here's a possible interpretation:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"vpn split tunnel settings\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"confirm vpn\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"vpn profile permissions\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "In this interpretation, each part is considered a step in a solution to a potential network issue. The first part involves adjusting VPN split tunnel settings, the second part involves confirming the VPN, and the third part involves checking VPN profile permissions.'\n",
      "Classifying and splitting rows:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 239/328 [16:07<07:49,  5.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 240/328 [16:09<06:25,  4.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 241/328 [16:12<05:55,  4.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 242/328 [16:15<05:05,  3.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 243/328 [16:17<04:28,  3.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet \"background update malware\", it's not clear if it's a symptom, cause, or solution. However, considering common network troubleshooting scenarios, \"background update malware\" could be interpreted as a cause for network issues. Therefore, the output would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"background update malware\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is based on the assumption that \"background update malware\" is a cause of network issues. If more context was provided, the classification could be different.'\n",
      "Classifying and splitting rows:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 244/328 [16:22<05:23,  3.86s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet \"issue dns misconfiguration\", it seems to be describing a problem or symptom rather than a cause or a solution. Therefore, the JSON object would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"issue dns misconfiguration\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This indicates that the text snippet is identified as a symptom (node_type: 0) of a potential network problem.'\n",
      "Classifying and splitting rows:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 245/328 [16:26<05:19,  3.85s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 246/328 [16:29<04:49,  3.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 247/328 [16:31<04:23,  3.26s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 248/328 [16:35<04:23,  3.29s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 249/328 [16:38<04:17,  3.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 250/328 [16:41<04:17,  3.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 251/328 [16:45<04:23,  3.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 252/328 [16:49<04:20,  3.43s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 253/328 [16:51<03:51,  3.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 254/328 [16:54<03:53,  3.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 255/328 [16:57<03:46,  3.10s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 256/328 [17:01<03:48,  3.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 257/328 [17:04<03:51,  3.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"hotels offer limit check wifi term\" seems to be a fragmented sentence and lacks context. However, if we were to make an assumption, it could be interpreted as follows:\n",
      "\n",
      "1. \"hotels offer limit\" - This could be seen as a cause, where the limitation offered by hotels might be causing an issue.\n",
      "2. \"check wifi term\" - This could be seen as a solution, suggesting to check the wifi term.\n",
      "\n",
      "Here is the JSON array of these objects:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"hotels offer limit\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"check wifi term\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is based on assumptions due to the lack of context and clear sentence structure in the provided text snippet.'\n",
      "Classifying and splitting rows:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 258/328 [17:13<05:53,  5.04s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided text snippet and keywords do not provide enough context to accurately classify the text into symptoms, causes, or solutions. The text \"issue month desk need buy package\" is too vague and does not clearly indicate a network troubleshooting context. Therefore, it's not possible to provide a JSON array of objects classifying the text into symptoms, causes, or solutions. More context or a more detailed text snippet would be needed to perform this task.'\n",
      "Classifying and splitting rows:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 259/328 [17:18<05:36,  4.88s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 260/328 [17:20<04:46,  4.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 261/328 [17:24<04:25,  3.96s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 262/328 [17:25<03:38,  3.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided text snippet \"vpn bypass check dedicate game vpn\" seems to be a solution or a method to a problem rather than a symptom or a cause. Therefore, the JSON object would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"vpn bypass check dedicate game vpn\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "This is because the text snippet is suggesting to check a dedicated game VPN for bypass, which is a solution to a potential problem.'\n",
      "Classifying and splitting rows:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 263/328 [17:30<03:51,  3.56s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"adapters interference verify check outdated wifi\", it's difficult to clearly separate the text into distinct parts of symptom, cause, or solution due to the lack of context and sentence structure. However, an attempt can be made to interpret the text as follows:\n",
      "\n",
      "1. \"adapters interference\" - This could be interpreted as a symptom where there is interference in the adapters.\n",
      "2. \"verify check\" - This could be seen as a solution where the user is advised to verify or check something.\n",
      "3. \"outdated wifi\" - This could be seen as a cause where the wifi being outdated is causing issues.\n",
      "\n",
      "The JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"adapters interference\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"verify check\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"outdated wifi\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is highly dependent on the context and the actual issues being discussed in the network troubleshooting text.'\n",
      "Classifying and splitting rows:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 264/328 [17:40<05:54,  5.54s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's not clear to classify it into distinct parts such as symptom, cause, or solution. The text \"newer wifi standards settings slow devices\" seems to be a statement or observation rather than a clear symptom, cause, or solution. Therefore, it's not possible to provide a JSON array of objects with \"node_type\" and \"text\" keys. More context or a more detailed text snippet would be needed to perform this task.'\n",
      "Classifying and splitting rows:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 265/328 [17:44<05:31,  5.27s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 266/328 [17:48<04:46,  4.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 267/328 [17:50<03:58,  3.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 268/328 [17:53<03:37,  3.63s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information seems to be incorrect. The keywords and labels extracted do not seem to match the text snippet provided. The text snippet \"switch udp tcp tcp protocol vpn vpn help stabilize\" seems to be a solution to a network problem, but without the context or the problem statement, it's hard to classify it accurately. \n",
      "\n",
      "However, assuming that the text snippet is a solution to a network problem, the JSON object would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"switch udp tcp tcp protocol vpn vpn help stabilize\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please provide the correct information or more context for a more accurate classification.'\n",
      "Classifying and splitting rows:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 269/328 [17:59<04:19,  4.39s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 270/328 [18:02<03:51,  3.99s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's not clear if it contains a symptom, a cause, or a solution. The text \"bandwidth network limit heavy bandwidth network\" seems to be a statement about a network condition, but it's not clear if this is a problem (symptom), a reason for a problem (cause), or a way to fix a problem (solution). \n",
      "\n",
      "Without additional context, it's not possible to accurately classify the text snippet. However, if we assume that this is a description of a problem, the output could be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"bandwidth network limit heavy bandwidth network\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "If more context was provided, it might be possible to identify additional parts of the text and classify them as symptoms, causes, or solutions.'\n",
      "Classifying and splitting rows:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 271/328 [18:10<04:55,  5.18s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 272/328 [18:12<04:01,  4.32s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 273/328 [18:15<03:35,  3.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 274/328 [18:19<03:31,  3.92s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 275/328 [18:22<03:12,  3.64s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"hotels limit session session length number\" seems to be incomplete and lacks context. Therefore, it's not possible to generate a JSON array of objects with \"node_type\" and \"text\" keys. \n",
      "\n",
      "For a more accurate classification, it would be helpful to have more context or a complete sentence. For instance, if the text snippet was \"Hotels limit the session length number to prevent network congestion\", we could classify \"Hotels limit the session length number\" as a solution (node_type: 2) and \"to prevent network congestion\" as a cause (node_type: 1). \n",
      "\n",
      "However, with the current information, it's not possible to provide a valid output.'\n",
      "Classifying and splitting rows:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 276/328 [18:29<03:59,  4.60s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided information is not sufficient to perform the task. The text snippet does not provide clear information about a network troubleshooting issue, and the keywords and labels do not seem to be related to the text snippet. Please provide a more detailed and coherent text snippet, keywords, and labels.'\n",
      "Classifying and splitting rows:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 277/328 [18:32<03:29,  4.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 278/328 [18:35<03:05,  3.71s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'As an AI model, I'm unable to process the data in real-time. However, I can provide you with a Python code snippet that you can use to process the data:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "# Given data\n",
      "text_snippet = \"wireguard protocol noticeable\"\n",
      "keywords_extracted = [' ', \"'\", ',', 'a', 'b', 'c', 'd', 'e', 'g', 'i', 'l', 'n', 'o', 'p', 'r', 't', 'u', 'w', '{', '}']\n",
      "labels_assigned = ['(', ')', 'e', 's', 't']\n",
      "\n",
      "# Assuming the text snippet is a symptom\n",
      "data = [{\n",
      "    \"node_type\": 0,  # 0 for symptom\n",
      "    \"text\": text_snippet\n",
      "}]\n",
      "\n",
      "# Convert the data to JSON\n",
      "json_data = json.dumps(data)\n",
      "\n",
      "# Print the JSON data\n",
      "print(json_data)\n",
      "```\n",
      "\n",
      "This code assumes that the given text snippet is a symptom. You can adjust the \"node_type\" value based on whether the text snippet is a symptom, a cause, or a solution. The \"node_type\" values are as follows: 0 for symptom, 1 for cause, and 2 for solution.'\n",
      "Classifying and splitting rows:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 279/328 [18:45<04:39,  5.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 280/328 [18:48<03:50,  4.79s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"battery optimization wifi wifi fix problem\" seems to be a mix of keywords rather than a coherent sentence or phrase. \n",
      "\n",
      "However, if we were to make an educated guess, we could interpret \"wifi fix problem\" as a symptom and \"battery optimization wifi\" as a potential solution. Here's how we could represent this in JSON:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"wifi fix problem\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"battery optimization wifi\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is highly speculative due to the lack of context and sentence structure in the original text snippet.'\n",
      "Classifying and splitting rows:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 281/328 [19:01<05:43,  7.31s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 282/328 [19:04<04:41,  6.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided text snippet does not seem to contain clear parts that can be classified as a symptom, a cause, or a solution. The text \"subscribe premium vpn specifically support stream premium vpn specifically\" appears to be a statement or a recommendation rather than a troubleshooting step or a problem description. Therefore, it's not possible to provide a JSON array of objects with \"node_type\" and \"text\" keys based on the given information.'\n",
      "Classifying and splitting rows:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 283/328 [19:08<04:09,  5.53s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 284/328 [19:12<03:42,  5.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 285/328 [19:20<04:05,  5.70s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 286/328 [19:22<03:22,  4.83s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts as symptoms, causes, or solutions due to the lack of context and sentence structure. However, assuming that the text is about using a hotspot device to avoid something, it can be interpreted as a solution. Here is the JSON object:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"use hotspot device hotspot device avoid\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 287/328 [19:27<03:20,  4.89s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 288/328 [19:30<02:45,  4.13s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided text snippet \"dedicate vpn server\" does not provide enough context to classify it as a symptom, cause, or solution. It seems to be a term or a concept related to network troubleshooting, but without additional context, it's not possible to determine whether it's describing a problem (symptom), a reason for a problem (cause), or a way to fix a problem (solution). Therefore, it's not possible to provide the requested JSON array of objects.'\n",
      "Classifying and splitting rows:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 289/328 [19:33<02:34,  3.97s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The given text snippet \"servers different vpn different vpn provider\" does not provide enough context to accurately classify it into symptom, cause, or solution. However, based on the limited information, it seems to be a description of a situation or configuration rather than a symptom, cause, or solution to a network problem. Therefore, it's challenging to provide a JSON array of objects classifying the snippet into symptom, cause, or solution. \n",
      "\n",
      "More context or information would be needed to accurately perform this task.'\n",
      "Classifying and splitting rows:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 290/328 [19:38<02:37,  4.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 291/328 [19:41<02:22,  3.86s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 292/328 [19:44<02:11,  3.64s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 293/328 [19:47<01:55,  3.30s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 294/328 [19:50<01:53,  3.34s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 295/328 [19:52<01:35,  2.91s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 296/328 [19:55<01:36,  3.01s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 297/328 [19:58<01:29,  2.88s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 298/328 [20:00<01:18,  2.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The provided text snippet \"different vpn server\" does not provide enough context to accurately classify it as a symptom, cause, or solution. However, in a general context, it could be interpreted as a solution to a problem. For example, if a user is having trouble connecting to a VPN, a possible solution could be to try a different VPN server. \n",
      "\n",
      "Here is the JSON object:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"different vpn server\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 299/328 [20:06<01:45,  3.65s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 300/328 [20:10<01:42,  3.66s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 301/328 [20:13<01:37,  3.60s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts that could be classified as a symptom, a cause, or a solution. The text snippet \"network session time wifi network session hotel wifi network\" seems to be a general description or statement rather than a troubleshooting scenario. \n",
      "\n",
      "However, if we were to make assumptions, we could interpret \"network session time\" as a potential symptom, and \"hotel wifi network\" as a potential cause. There's no clear solution provided in the text. \n",
      "\n",
      "Here's how we could represent this in JSON:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"network session time\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"hotel wifi network\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation is highly speculative due to the lack of context and clear troubleshooting elements in the provided text snippet.'\n",
      "Classifying and splitting rows:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 302/328 [20:22<02:17,  5.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it seems there is only one distinct part which is a solution. The text \"hotspot solve connectivity personal hotspot solve\" suggests a solution to a connectivity issue using a personal hotspot. However, without more context, it's difficult to accurately classify the text. Here is the JSON object:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"hotspot solve connectivity personal hotspot solve\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 303/328 [20:26<02:01,  4.87s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 304/328 [20:29<01:40,  4.17s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 305/328 [20:32<01:32,  4.02s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 306/328 [20:35<01:18,  3.58s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 307/328 [20:38<01:11,  3.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 308/328 [20:42<01:09,  3.49s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 309/328 [20:45<01:05,  3.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'The given text snippet \"uninstalling driver completely\" is a solution to a problem. Therefore, the JSON object would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"uninstalling driver completely\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 310/328 [20:49<01:03,  3.51s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 311/328 [20:51<00:55,  3.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 312/328 [20:54<00:51,  3.21s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 313/328 [20:57<00:44,  2.96s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"disable power save\", it appears to be a solution to a potential problem. There is no symptom or cause mentioned in this snippet. Therefore, the JSON object would be:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"disable power save\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 314/328 [21:00<00:41,  2.97s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 315/328 [21:03<00:37,  2.90s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'As an AI model, I can't directly interact with the data. However, I can guide you on how to approach this task. \n",
      "\n",
      "The text snippet \"drivers qos settings\" seems to be a single part, and it's likely referring to a solution or a cause. However, without more context, it's hard to definitively classify it. \n",
      "\n",
      "Here's a Python code snippet that creates the desired JSON array:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "# Assuming the text snippet is a solution\n",
      "data = [\n",
      "    {\n",
      "        \"node_type\": 2,  # 2 stands for solution\n",
      "        \"text\": \"drivers qos settings\"\n",
      "    }\n",
      "]\n",
      "\n",
      "json_data = json.dumps(data)\n",
      "print(json_data)\n",
      "```\n",
      "\n",
      "This will output:\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"node_type\": 2,\n",
      "        \"text\": \"drivers qos settings\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n",
      "You can adjust the \"node_type\" value based on whether you classify the text snippet as a symptom (0), a cause (1), or a solution (2).'\n",
      "Classifying and splitting rows:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 316/328 [21:11<00:54,  4.57s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 317/328 [21:14<00:45,  4.15s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 318/328 [21:17<00:36,  3.62s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 319/328 [21:19<00:29,  3.25s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 320/328 [21:22<00:24,  3.11s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Given the text snippet \"auto reconnect issue\", it seems to be describing a symptom of a problem. There is no cause or solution mentioned in the snippet. Therefore, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"auto reconnect issue\"\n",
      "  }\n",
      "]\n",
      "```'\n",
      "Classifying and splitting rows:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 321/328 [21:25<00:21,  3.12s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 322/328 [21:28<00:17,  2.99s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 323/328 [21:30<00:14,  2.83s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 324/328 [21:33<00:11,  2.94s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 325/328 [21:37<00:09,  3.09s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 326/328 [21:39<00:05,  2.99s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the provided text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet \"feature stop packet packet loss thank\" seems to be incomplete and lacks context. However, if we assume that \"packet loss\" is a symptom and \"feature stop packet\" is a solution, the JSON array would look like this:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"packet loss\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"feature stop packet\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Please note that this interpretation might not be accurate due to the lack of context and the fragmented nature of the text snippet.'\n",
      "Classifying and splitting rows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 327/328 [21:45<00:03,  3.84s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:text_classification:Failed to parse model output as JSON: 'Based on the given text snippet, it's difficult to clearly identify distinct parts and classify them as a symptom, a cause, or a solution. The text snippet seems to be a list of actions or steps rather than a clear description of a problem, its cause, or its solution. However, an attempt can be made to interpret the given text as follows:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"node_type\": 0,\n",
      "    \"text\": \"check update\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 1,\n",
      "    \"text\": \"disable host network\"\n",
      "  },\n",
      "  {\n",
      "    \"node_type\": 2,\n",
      "    \"text\": \"disable network feature driver\"\n",
      "  }\n",
      "]\n",
      "\n",
      "In this interpretation, \"check update\" is classified as a symptom (node_type: 0), suggesting that the user may be experiencing issues with updates. \"Disable host network\" is classified as a cause (node_type: 1), suggesting that the host network may be causing the issue. Finally, \"disable network feature driver\" is classified as a solution (node_type: 2), suggesting that disabling the network feature driver may resolve the issue.'\n",
      "Classifying and splitting rows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 328/328 [21:56<00:00,  5.85s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 328/328 [21:59<00:00,  4.02s/it]\n"
     ]
    }
   ],
   "source": [
    "classification_method = \"openai\"\n",
    "df = classify_text(df, classification_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f\"./output/{classification_method}_classified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c64949",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_method = \"openai\"\n",
    "df = pd.read_csv(f\"./output/{classification_method}_classified.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ad504b",
   "metadata": {},
   "source": [
    "### üè∑Ô∏è  `generate_node_names()` ‚Äî why we need it\n",
    "\n",
    "* **Merge near-duplicates**  \n",
    "  *Embeds* each `segment + labels + keywords`, clusters with **HDBSCAN** ‚Üí one ‚ÄúWi-Fi timeout‚Äù node instead of 200 synonymous sentences.\n",
    "\n",
    "* **Readable graph labels**  \n",
    "  Picks the most central items in every cluster (or the lone outliers) and asks GPT to coin a **short, human name**.\n",
    "\n",
    "* **Query-friendly format**  \n",
    "  A second GPT pass converts those names to **snake_case** (`wifi_timeout`, `dns_misconfig`) ‚Äì perfect for Cypher, dashboards, or APIs.\n",
    "\n",
    "* **Parameter knobs**  \n",
    "  - Swap embedding backend (`openai`, etc.)  \n",
    "  - Tune cluster granularity (`min_cluster_size`)  \n",
    "  - Plug in another LLM or offline namer later.\n",
    "\n",
    "Result: the DataFrame returns with a single `node_name` column‚Äîdeduplicated, concise, and machine-friendly‚Äîready to be loaded as graph nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "923e0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from node_name_generator import generate_node_names\n",
    "\n",
    "\n",
    "df = generate_node_names(\n",
    "    df,\n",
    "    embedding_type=\"openai\",  # or \"bert\", \"tfidf\", etc.\n",
    "    output_path=\"./output/node_names.csv\",  # optional path for saving embeddings\n",
    "    clustering_method=\"hdbscan\",\n",
    "    clustering_params={\"min_cluster_size\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"./output/node_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ebb24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./output/node_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f016cf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_type</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>source</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>node_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>post002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Wi-Fi signal drops frequently when I move arou...</td>\n",
       "      <td>wifi_connectivity_troubleshooting_kit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>post002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Whenever I go to the basement or the far end o...</td>\n",
       "      <td>wifi_connectivity_troubleshooting_kit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>post002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Whenever I go to the basement or the far end o...</td>\n",
       "      <td>wifi_connectivity_troubleshooting_kit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>post002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Whenever I go to the basement or the far end o...</td>\n",
       "      <td>network_driver_update_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>post003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Ping is fine but I can't load certain websites...</td>\n",
       "      <td>wifi_connectivity_troubleshooting_kit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1</td>\n",
       "      <td>post106</td>\n",
       "      <td>c157</td>\n",
       "      <td>2</td>\n",
       "      <td>Packet loss can be driver-related; try disabli...</td>\n",
       "      <td>network_driver_update_cluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>2</td>\n",
       "      <td>post106</td>\n",
       "      <td>c157</td>\n",
       "      <td>2</td>\n",
       "      <td>Packet loss can be driver-related; try disabli...</td>\n",
       "      <td>large_packet_send_offload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0</td>\n",
       "      <td>post107</td>\n",
       "      <td>c160</td>\n",
       "      <td>2</td>\n",
       "      <td>Enabling hosted network in driver properties f...</td>\n",
       "      <td>wifi_connectivity_troubleshooting_kit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>2</td>\n",
       "      <td>post107</td>\n",
       "      <td>c160</td>\n",
       "      <td>2</td>\n",
       "      <td>Enabling hosted network in driver properties f...</td>\n",
       "      <td>network_hotspot_properties_fixer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>2</td>\n",
       "      <td>post107</td>\n",
       "      <td>c160</td>\n",
       "      <td>2</td>\n",
       "      <td>Enabling hosted network in driver properties f...</td>\n",
       "      <td>wireless_driver_management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     node_type  post_id comment_id  source  \\\n",
       "0            0  post002        NaN       0   \n",
       "1            0  post002        NaN       1   \n",
       "2            0  post002        NaN       1   \n",
       "3            1  post002        NaN       1   \n",
       "4            0  post003        NaN       0   \n",
       "..         ...      ...        ...     ...   \n",
       "419          1  post106       c157       2   \n",
       "420          2  post106       c157       2   \n",
       "421          0  post107       c160       2   \n",
       "422          2  post107       c160       2   \n",
       "423          2  post107       c160       2   \n",
       "\n",
       "                                             text_orig  \\\n",
       "0    Wi-Fi signal drops frequently when I move arou...   \n",
       "1    Whenever I go to the basement or the far end o...   \n",
       "2    Whenever I go to the basement or the far end o...   \n",
       "3    Whenever I go to the basement or the far end o...   \n",
       "4    Ping is fine but I can't load certain websites...   \n",
       "..                                                 ...   \n",
       "419  Packet loss can be driver-related; try disabli...   \n",
       "420  Packet loss can be driver-related; try disabli...   \n",
       "421  Enabling hosted network in driver properties f...   \n",
       "422  Enabling hosted network in driver properties f...   \n",
       "423  Enabling hosted network in driver properties f...   \n",
       "\n",
       "                                 node_name  \n",
       "0    wifi_connectivity_troubleshooting_kit  \n",
       "1    wifi_connectivity_troubleshooting_kit  \n",
       "2    wifi_connectivity_troubleshooting_kit  \n",
       "3            network_driver_update_cluster  \n",
       "4    wifi_connectivity_troubleshooting_kit  \n",
       "..                                     ...  \n",
       "419          network_driver_update_cluster  \n",
       "420              large_packet_send_offload  \n",
       "421  wifi_connectivity_troubleshooting_kit  \n",
       "422       network_hotspot_properties_fixer  \n",
       "423             wireless_driver_management  \n",
       "\n",
       "[424 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd275102",
   "metadata": {},
   "source": [
    "## Knowledge Graph Construction\n",
    "\n",
    "###  Directed, Labelled Graph (Boring üëéüèª)\n",
    "A graph can be formalised as the tuple  $G = (V, E, s, t, \\ell_V, \\ell_E)$:\n",
    "\n",
    "\\begin{aligned}\n",
    "V       &\\;=\\; \\text{finite set of vertices (nodes)}, \\\\[4pt]\n",
    "E       &\\;\\subseteq\\; V \\times V \\;=\\; \\text{finite set of edges}, \\\\[4pt]\n",
    "s : E \\to V &\\; \\text{source map (gives the start‚Äêvertex of each edge)}, \\\\[4pt]\n",
    "t : E \\to V &\\; \\text{target map (gives the end‚Äêvertex of each edge)}, \\\\[4pt]\n",
    "\\ell_V : V \\to \\Sigma_V &\\; \\text{vertex‚Äìlabelling function}, \\\\[4pt]\n",
    "\\ell_E : E \\to \\Sigma_E &\\; \\text{edge‚Äìlabelling function}.\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d839c",
   "metadata": {},
   "source": [
    "### Our Graph (Lovely üíñü§åüèªü§åüèªü§åüèª)\n",
    "<!-- ‚ú® Pretty-printed tables: baby-pink nodes, pastel-green edges -->\n",
    "<style>\n",
    "  /* NODE table ‚Äî light baby-pink */\n",
    "  .node-table {\n",
    "    border: 2px solid #ffb6c1;       /* baby-pink border */\n",
    "    border-collapse: collapse;\n",
    "    width: 100%;\n",
    "  }\n",
    "  .node-table th, .node-table td {\n",
    "    border: 1px solid #ffb6c1;\n",
    "    padding: 8px;\n",
    "    text-align: left;\n",
    "  }\n",
    "  .node-table th {\n",
    "    background: rgba(255, 182, 193, 0.35); /* baby-pink header with mild opacity */\n",
    "  }\n",
    "\n",
    "  /* EDGE table ‚Äî pastel-green */\n",
    "  .edge-table {\n",
    "    border: 2px solid #a7f5a7;       /* pastel-green border */\n",
    "    border-collapse: collapse;\n",
    "    width: 100%;\n",
    "    margin-top: 24px;\n",
    "  }\n",
    "  .edge-table th, .edge-table td {\n",
    "    border: 1px solid #a7f5a7;\n",
    "    padding: 8px;\n",
    "    text-align: left;\n",
    "  }\n",
    "  .edge-table th {\n",
    "    background: rgba(167, 245, 167, 0.35); /* pastel-green header with mild opacity */\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<table class=\"node-table\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th><strong>Node Label</strong></th>\n",
    "      <th><strong>Description</strong></th>\n",
    "      <th><strong>Example value for <code>name</code></strong></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td><code>Post</code></td>\n",
    "      <td>An individual support request / forum post.</td>\n",
    "      <td>N/A</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>Symptom</code></td>\n",
    "      <td>A specific problem characteristic reported.</td>\n",
    "      <td><code>no_website_access</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>Cause</code></td>\n",
    "      <td>A potential root cause of one or more symptoms.</td>\n",
    "      <td><code>dns_misconfiguration</code></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>Solution</code></td>\n",
    "      <td>A suggested fix or troubleshooting step.</td>\n",
    "      <td><code>flush_dns_cache</code></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "<!-- EDGE TABLE -->\n",
    "<table class=\"edge-table\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th><strong>Relationship Type</strong></th>\n",
    "      <th><strong>Start Node</strong></th>\n",
    "      <th><strong>End Node</strong></th>\n",
    "      <th><strong>Description</strong></th>\n",
    "      <th><strong>Key Properties&nbsp;(type)</strong></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td><code>REPORTS_SYMPTOM</code></td>\n",
    "      <td>Post</td>\n",
    "      <td>Symptom</td>\n",
    "      <td>Symptom described in the post.</td>\n",
    "      <td><code>context: string</code> (optional snippet)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>SUGGESTS_CAUSE</code></td>\n",
    "      <td>Post</td>\n",
    "      <td>Cause</td>\n",
    "      <td>Cause suggested in a reply.</td>\n",
    "      <td><code>replySource: string</code>, <code>strength: float</code> (optional)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>SUGGESTS_SOLUTION</code></td>\n",
    "      <td>Post</td>\n",
    "      <td>Solution</td>\n",
    "      <td>Solution suggested in a reply.</td>\n",
    "      <td><code>replySource: string</code>, <code>strength: float</code> (optional)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>HAS_ASSOCIATED_CAUSE</code></td>\n",
    "      <td>Symptom</td>\n",
    "      <td>Cause</td>\n",
    "      <td>(Derived) Symptom‚Äìcause pair frequently linked.</td>\n",
    "      <td><code>frequency: integer</code>, <code>confidence: float</code> (optional)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>SYMPTOM_COCCURS</code></td>\n",
    "      <td>Symptom</td>\n",
    "      <td>Symptom</td>\n",
    "      <td>(Derived) Two symptoms often co-occur.</td>\n",
    "      <td><code>frequency: integer</code>, <code>lift: float</code> (optional)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><code>CAUSE_ADDRESSED_BY</code></td>\n",
    "      <td>Cause</td>\n",
    "      <td>Solution</td>\n",
    "      <td>(Derived) Solution known to fix the cause.</td>\n",
    "      <td><code>frequency: integer</code></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a5764d",
   "metadata": {},
   "source": [
    "### Cypher Query: `symptom_query`\n",
    "\n",
    "üìã **The Query**\n",
    "\n",
    "```cypher\n",
    "MERGE (s:Symptom {name: $props.name})\n",
    "ON CREATE SET s += $props, s.created_at = timestamp()\n",
    "ON MATCH  SET s += $props, s.updated_at = timestamp()\n",
    "```\n",
    "\n",
    "> **Purpose:** Ensure a unique `Symptom` node by its `name`, create it if missing, and update properties/timestamps appropriately.\n",
    "\n",
    "üéØ **Why Use This Pattern?**\n",
    "\n",
    "* **Idempotency:** Running the same query repeatedly won‚Äôt create duplicate nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11021d15",
   "metadata": {},
   "source": [
    "### üåê Relationship Query: `rel_query`\n",
    "\n",
    "```cypher\n",
    "MATCH (postNode:Post {postId: $postId})\n",
    "MATCH (symptomNode:Symptom {name: $node_name})\n",
    "MERGE (postNode)-[describesRel:DESCRIBES_SYMPTOM]->(symptomNode)\n",
    "SET describesRel = $props\n",
    "```\n",
    "\n",
    "> **Purpose:** Link a `Post` to a `Symptom` via a `DESCRIBES_SYMPTOM` relationship, ensuring it exists and updating its properties.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Why Use This Pattern?\n",
    "\n",
    "* **Co-occurrence Analysis:** Quickly identify frequently co-mentioned symptoms.\n",
    "* **Efficient Counting:** By incrementing `weight`, you avoid expensive aggregation queries over large datasets.\n",
    "* **Avoid Duplicate Relationships:** The `WHERE id(s1) < id(s2)` convention and `MERGE` ensure one relationship per unordered pair.\n",
    "* **Dynamic Updates:** Each new post automatically adjusts relationship weights, keeping metrics up to date.\n",
    "\n",
    "---\n",
    "\n",
    "*This polished explanation should help convey both the intent and mechanics of the co-occurrence query in a clear, visually appealing way.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a800f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<img src=\"./images/er_diagram.jpg\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e28568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Successfully connected to Neo4j database.\n",
      "INFO:root:Database cleared successfully.\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Post) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_49c43cbc FOR (e:Post) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (p:Post) REQUIRE p.id IS UNIQUE'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Symptom) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_baf64ff0 FOR (e:Symptom) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (s:Symptom) REQUIRE s.name IS UNIQUE'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Cause) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_e9f62385 FOR (e:Cause) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (c:Cause) REQUIRE c.name IS UNIQUE'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:Treatment) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_9a88938c FOR (e:Treatment) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (sol:Treatment) REQUIRE sol.name IS UNIQUE'\n",
      "INFO:root:Constraints created or already exist.\n",
      "INFO:root:Preparing DataFrame. Columns found: ['node_type', 'post_id', 'comment_id', 'source', 'text_orig', 'node_name']\n",
      "INFO:root:'labels' column not found, will be ignored.\n",
      "INFO:root:'keywords' column not found, will be ignored.\n",
      "INFO:root:'segment' column not found, will be ignored.\n",
      "INFO:root:DataFrame preparation complete. 'labels', 'keywords', and 'segment' will not be used.\n",
      "INFO:root:Starting to populate graph with 424 rows using pre-grouping...\n",
      "INFO:root:Ensured all 89 Post nodes exist with initial frequency.\n",
      "INFO:root:Pre-grouped data for 89 posts.\n",
      "INFO:root:Processed linking for approx 100/301 S/C/T items...\n",
      "INFO:root:Processed linking for approx 301/301 S/C/T items...\n",
      "INFO:root:Finished populating graph with primary nodes and relationships using pre-grouping.\n",
      "INFO:root:Created/updated SYMPTOM_COOCCURS relationships.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from graph_generator import (\n",
    "    Neo4jUploader,\n",
    ")\n",
    "\n",
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"cheesecake\"\n",
    "\n",
    "uploader = Neo4jUploader(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "uploader.clear_database_interactive()\n",
    "uploader.create_constraints()\n",
    "uploader.populate_graph_from_dataframe(df)\n",
    "uploader.create_symptom_cooccurrence_relationships()\n",
    "# uploader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44879ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_json_file_path = \"./data/small.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f93a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_lemmatizing = True\n",
    "do_stemming = False\n",
    "keyword_method = \"keybert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5017ba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aleynakara/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aleynakara/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aleynakara/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/Users/aleynakara/miniconda3/envs/symp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-04 16:59:55,855 - INFO - PyTorch version 2.5.1 available.\n",
      "/Users/aleynakara/miniconda3/envs/symp/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "2025-06-04 16:59:57,321 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "2025-06-04 16:59:57,376 - INFO - Use pytorch device_name: mps\n",
      "2025-06-04 16:59:57,377 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "from load_data import json_to_dataframes, TEXT_COL\n",
    "from preprocess import preprocess_text\n",
    "from keyword_extraction import extract_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4cde89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = json_to_dataframes(inference_json_file_path)\n",
    "inference_df = preprocess_text(\n",
    "    inference_df, TEXT_COL, do_stemming=do_stemming, do_lemmatizing=do_lemmatizing\n",
    ")\n",
    "inference_df = extract_keywords(inference_df, TEXT_COL, method=keyword_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212710c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>struggle log train train service website</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>struggle log train service website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>load strangely browse access train login websi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>{vpn, today}</td>\n",
       "      <td>{date, protocol}</td>\n",
       "      <td>try access train login page today keep spin wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>post001</td>\n",
       "      <td>ITSupportAnna</td>\n",
       "      <td>vpns cause issue try turn check issue specific...</td>\n",
       "      <td>2</td>\n",
       "      <td>c001</td>\n",
       "      <td>VPNs often cause issues with specific sites. T...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>vpns often cause issue specific sit try turn c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post001</td>\n",
       "      <td>NetworkNils</td>\n",
       "      <td>cache cookies cause browser cache cookies</td>\n",
       "      <td>2</td>\n",
       "      <td>c002</td>\n",
       "      <td>Sometimes browser cache or cookies cause loadi...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>sometimes browser cache cookies cause load iss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id              user  \\\n",
       "0  post001  TrainTravelerMax   \n",
       "1  post001  TrainTravelerMax   \n",
       "2  post001     ITSupportAnna   \n",
       "3  post001       NetworkNils   \n",
       "\n",
       "                                                text  source comment_id  \\\n",
       "0           struggle log train train service website       0        NaN   \n",
       "1  load strangely browse access train login websi...       1        NaN   \n",
       "2  vpns cause issue try turn check issue specific...       2       c001   \n",
       "3          cache cookies cause browser cache cookies       2       c002   \n",
       "\n",
       "                                           text_orig      keywords  \\\n",
       "0   Struggling to log into the train service website            {}   \n",
       "1  I tried accessing the train login page today b...  {vpn, today}   \n",
       "2  VPNs often cause issues with specific sites. T...            {}   \n",
       "3  Sometimes browser cache or cookies cause loadi...            {}   \n",
       "\n",
       "             labels                                         text_clean  \n",
       "0                {}                 struggle log train service website  \n",
       "1  {date, protocol}  try access train login page today keep spin wi...  \n",
       "2                {}  vpns often cause issue specific sit try turn c...  \n",
       "3                {}  sometimes browser cache cookies cause load iss...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20583d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df.drop(columns=[\"text_clean\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dc63fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df.to_csv(\"./output/inference_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5081909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "keyword_method = \"keybert\"\n",
    "inference_df = pd.read_csv(\"./output/inference_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2993e8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>keywords</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>struggle log train train service website</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>set()</td>\n",
       "      <td>set()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>post001</td>\n",
       "      <td>TrainTravelerMax</td>\n",
       "      <td>load strangely browse access train login websi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>{'vpn', 'today'}</td>\n",
       "      <td>{'date', 'protocol'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>post001</td>\n",
       "      <td>ITSupportAnna</td>\n",
       "      <td>vpns cause issue try turn check issue specific...</td>\n",
       "      <td>2</td>\n",
       "      <td>c001</td>\n",
       "      <td>VPNs often cause issues with specific sites. T...</td>\n",
       "      <td>set()</td>\n",
       "      <td>set()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post001</td>\n",
       "      <td>NetworkNils</td>\n",
       "      <td>cache cookies cause browser cache cookies</td>\n",
       "      <td>2</td>\n",
       "      <td>c002</td>\n",
       "      <td>Sometimes browser cache or cookies cause loadi...</td>\n",
       "      <td>set()</td>\n",
       "      <td>set()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id              user  \\\n",
       "0  post001  TrainTravelerMax   \n",
       "1  post001  TrainTravelerMax   \n",
       "2  post001     ITSupportAnna   \n",
       "3  post001       NetworkNils   \n",
       "\n",
       "                                                text  source comment_id  \\\n",
       "0           struggle log train train service website       0        NaN   \n",
       "1  load strangely browse access train login websi...       1        NaN   \n",
       "2  vpns cause issue try turn check issue specific...       2       c001   \n",
       "3          cache cookies cause browser cache cookies       2       c002   \n",
       "\n",
       "                                           text_orig          keywords  \\\n",
       "0   Struggling to log into the train service website             set()   \n",
       "1  I tried accessing the train login page today b...  {'vpn', 'today'}   \n",
       "2  VPNs often cause issues with specific sites. T...             set()   \n",
       "3  Sometimes browser cache or cookies cause loadi...             set()   \n",
       "\n",
       "                 labels  \n",
       "0                 set()  \n",
       "1  {'date', 'protocol'}  \n",
       "2                 set()  \n",
       "3                 set()  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168b4f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the STANFORDTOOLSDIR environment variable\n",
    "os.environ[\"STANFORDTOOLSDIR\"] = os.path.expanduser(\"~/stanford-ner-2015-12-09\")\n",
    "# Set the CLASSPATH to the Stanford NER jar\n",
    "os.environ[\"CLASSPATH\"] = os.path.join(\n",
    "    os.environ[\"STANFORDTOOLSDIR\"], \"stanford-ner.jar\"\n",
    ")\n",
    "# Set the STANFORD_MODELS to the classifiers directory\n",
    "os.environ[\"STANFORD_MODELS\"] = os.path.join(\n",
    "    os.environ[\"STANFORDTOOLSDIR\"], \"classifiers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b943580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleynakara/miniconda3/envs/symp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aleynakara/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aleynakara/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aleynakara/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Some weights of the model checkpoint at jackaduma/SecBERT were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from ner import extract_entities_from_dataframes\n",
    "\n",
    "ner_method = \"stanford\"\n",
    "inference_df = extract_entities_from_dataframes(inference_df, method=ner_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b67b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>source</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>struggle log train train service website</td>\n",
       "      <td>{website, service, struggle, train, log}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>{'date', 'protocol'}</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>load strangely browse access train login websi...</td>\n",
       "      <td>{fine, train, browse, access, websites, vpn, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>post001</td>\n",
       "      <td>c001</td>\n",
       "      <td>2</td>\n",
       "      <td>set()</td>\n",
       "      <td>VPNs often cause issues with specific sites. T...</td>\n",
       "      <td>vpns cause issue try turn check issue specific...</td>\n",
       "      <td>{sit, vpns, turn, cause, try, check, issue, sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>post001</td>\n",
       "      <td>c002</td>\n",
       "      <td>2</td>\n",
       "      <td>set()</td>\n",
       "      <td>Sometimes browser cache or cookies cause loadi...</td>\n",
       "      <td>cache cookies cause browser cache cookies</td>\n",
       "      <td>{cause, cache, cookies, browser}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id comment_id  source                labels  \\\n",
       "0  post001        NaN       0                 set()   \n",
       "1  post001        NaN       1  {'date', 'protocol'}   \n",
       "2  post001       c001       2                 set()   \n",
       "3  post001       c002       2                 set()   \n",
       "\n",
       "                                           text_orig  \\\n",
       "0   Struggling to log into the train service website   \n",
       "1  I tried accessing the train login page today b...   \n",
       "2  VPNs often cause issues with specific sites. T...   \n",
       "3  Sometimes browser cache or cookies cause loadi...   \n",
       "\n",
       "                                                text  \\\n",
       "0           struggle log train train service website   \n",
       "1  load strangely browse access train login websi...   \n",
       "2  vpns cause issue try turn check issue specific...   \n",
       "3          cache cookies cause browser cache cookies   \n",
       "\n",
       "                                            keywords  \n",
       "0           {website, service, struggle, train, log}  \n",
       "1  {fine, train, browse, access, websites, vpn, l...  \n",
       "2  {sit, vpns, turn, cause, try, check, issue, sp...  \n",
       "3                   {cause, cache, cookies, browser}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5fb06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying and splitting rows:   0%|          | 0/4 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:04<00:04,  2.08s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:07<00:02,  2.72s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:12<00:00,  3.55s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Classifying and splitting rows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:15<00:00,  3.97s/it]\n"
     ]
    }
   ],
   "source": [
    "from text_classification import classify_text\n",
    "\n",
    "classification_method = \"openai\"\n",
    "inference_df = classify_text(inference_df, classification_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292ae5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df.to_csv(\"./output/inference_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13733618",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = pd.read_csv(\"./output/inference_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3e6301e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>node_type</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>source</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>struggle log train</td>\n",
       "      <td>0</td>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>{'website', 'service', 'struggle', 'train', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train service</td>\n",
       "      <td>1</td>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>{'website', 'service', 'struggle', 'train', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service website</td>\n",
       "      <td>2</td>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>set()</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>{'website', 'service', 'struggle', 'train', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>load strangely browse access train login websi...</td>\n",
       "      <td>0</td>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>{'date', 'protocol'}</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>{'fine', 'train', 'browse', 'access', 'website...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vpn</td>\n",
       "      <td>1</td>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>{'date', 'protocol'}</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>{'fine', 'train', 'browse', 'access', 'website...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vpns cause issue</td>\n",
       "      <td>0</td>\n",
       "      <td>post001</td>\n",
       "      <td>c001</td>\n",
       "      <td>2</td>\n",
       "      <td>set()</td>\n",
       "      <td>VPNs often cause issues with specific sites. T...</td>\n",
       "      <td>{'sit', 'vpns', 'turn', 'cause', 'try', 'check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>try turn check issue</td>\n",
       "      <td>2</td>\n",
       "      <td>post001</td>\n",
       "      <td>c001</td>\n",
       "      <td>2</td>\n",
       "      <td>set()</td>\n",
       "      <td>VPNs often cause issues with specific sites. T...</td>\n",
       "      <td>{'sit', 'vpns', 'turn', 'cause', 'try', 'check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>specific sit</td>\n",
       "      <td>1</td>\n",
       "      <td>post001</td>\n",
       "      <td>c001</td>\n",
       "      <td>2</td>\n",
       "      <td>set()</td>\n",
       "      <td>VPNs often cause issues with specific sites. T...</td>\n",
       "      <td>{'sit', 'vpns', 'turn', 'cause', 'try', 'check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cache cookies cause</td>\n",
       "      <td>0</td>\n",
       "      <td>post001</td>\n",
       "      <td>c002</td>\n",
       "      <td>2</td>\n",
       "      <td>set()</td>\n",
       "      <td>Sometimes browser cache or cookies cause loadi...</td>\n",
       "      <td>{'cause', 'cache', 'cookies', 'browser'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>browser cache cookies</td>\n",
       "      <td>1</td>\n",
       "      <td>post001</td>\n",
       "      <td>c002</td>\n",
       "      <td>2</td>\n",
       "      <td>set()</td>\n",
       "      <td>Sometimes browser cache or cookies cause loadi...</td>\n",
       "      <td>{'cause', 'cache', 'cookies', 'browser'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             segment  node_type  post_id  \\\n",
       "0                                 struggle log train          0  post001   \n",
       "1                                      train service          1  post001   \n",
       "2                                    service website          2  post001   \n",
       "3  load strangely browse access train login websi...          0  post001   \n",
       "4                                                vpn          1  post001   \n",
       "5                                   vpns cause issue          0  post001   \n",
       "6                               try turn check issue          2  post001   \n",
       "7                                       specific sit          1  post001   \n",
       "8                                cache cookies cause          0  post001   \n",
       "9                              browser cache cookies          1  post001   \n",
       "\n",
       "  comment_id  source                labels  \\\n",
       "0        NaN       0                 set()   \n",
       "1        NaN       0                 set()   \n",
       "2        NaN       0                 set()   \n",
       "3        NaN       1  {'date', 'protocol'}   \n",
       "4        NaN       1  {'date', 'protocol'}   \n",
       "5       c001       2                 set()   \n",
       "6       c001       2                 set()   \n",
       "7       c001       2                 set()   \n",
       "8       c002       2                 set()   \n",
       "9       c002       2                 set()   \n",
       "\n",
       "                                           text_orig  \\\n",
       "0   Struggling to log into the train service website   \n",
       "1   Struggling to log into the train service website   \n",
       "2   Struggling to log into the train service website   \n",
       "3  I tried accessing the train login page today b...   \n",
       "4  I tried accessing the train login page today b...   \n",
       "5  VPNs often cause issues with specific sites. T...   \n",
       "6  VPNs often cause issues with specific sites. T...   \n",
       "7  VPNs often cause issues with specific sites. T...   \n",
       "8  Sometimes browser cache or cookies cause loadi...   \n",
       "9  Sometimes browser cache or cookies cause loadi...   \n",
       "\n",
       "                                            keywords  \n",
       "0  {'website', 'service', 'struggle', 'train', 'l...  \n",
       "1  {'website', 'service', 'struggle', 'train', 'l...  \n",
       "2  {'website', 'service', 'struggle', 'train', 'l...  \n",
       "3  {'fine', 'train', 'browse', 'access', 'website...  \n",
       "4  {'fine', 'train', 'browse', 'access', 'website...  \n",
       "5  {'sit', 'vpns', 'turn', 'cause', 'try', 'check...  \n",
       "6  {'sit', 'vpns', 'turn', 'cause', 'try', 'check...  \n",
       "7  {'sit', 'vpns', 'turn', 'cause', 'try', 'check...  \n",
       "8           {'cause', 'cache', 'cookies', 'browser'}  \n",
       "9           {'cause', 'cache', 'cookies', 'browser'}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bca5d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "/Users/aleynakara/miniconda3/envs/symp/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/aleynakara/miniconda3/envs/symp/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "/Users/aleynakara/miniconda3/envs/symp/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/aleynakara/miniconda3/envs/symp/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "/Users/aleynakara/miniconda3/envs/symp/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/aleynakara/miniconda3/envs/symp/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from node_name_generator import generate_node_names\n",
    "\n",
    "\n",
    "inference_df = generate_node_names(\n",
    "    inference_df,\n",
    "    embedding_type=\"openai\",  # or \"bert\", \"tfidf\", etc.\n",
    "    output_path=\"./output/inference_node_names.csv\",  # optional path for saving embeddings\n",
    "    clustering_method=\"hdbscan\",\n",
    "    clustering_params={\"min_cluster_size\": 2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cf827f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_type</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>source</th>\n",
       "      <th>text_orig</th>\n",
       "      <th>node_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>struggle_train_log_service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>train_logistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Struggling to log into the train service website</td>\n",
       "      <td>service_logix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>secure_web_access_protocol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>post001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>I tried accessing the train login page today b...</td>\n",
       "      <td>secure_access_suite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>post001</td>\n",
       "      <td>c001</td>\n",
       "      <td>2</td>\n",
       "      <td>VPNs often cause issues with specific sites. T...</td>\n",
       "      <td>vpn_troubleshooting_guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>post001</td>\n",
       "      <td>c001</td>\n",
       "      <td>2</td>\n",
       "      <td>VPNs often cause issues with specific sites. T...</td>\n",
       "      <td>troubleshoot_task_manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>post001</td>\n",
       "      <td>c001</td>\n",
       "      <td>2</td>\n",
       "      <td>VPNs often cause issues with specific sites. T...</td>\n",
       "      <td>solve_sit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>post001</td>\n",
       "      <td>c002</td>\n",
       "      <td>2</td>\n",
       "      <td>Sometimes browser cache or cookies cause loadi...</td>\n",
       "      <td>cache_cookie_cause_resolver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>post001</td>\n",
       "      <td>c002</td>\n",
       "      <td>2</td>\n",
       "      <td>Sometimes browser cache or cookies cause loadi...</td>\n",
       "      <td>cache_cookie_setter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_type  post_id comment_id  source  \\\n",
       "0          0  post001        NaN       0   \n",
       "1          1  post001        NaN       0   \n",
       "2          2  post001        NaN       0   \n",
       "3          0  post001        NaN       1   \n",
       "4          1  post001        NaN       1   \n",
       "5          0  post001       c001       2   \n",
       "6          2  post001       c001       2   \n",
       "7          1  post001       c001       2   \n",
       "8          0  post001       c002       2   \n",
       "9          1  post001       c002       2   \n",
       "\n",
       "                                           text_orig  \\\n",
       "0   Struggling to log into the train service website   \n",
       "1   Struggling to log into the train service website   \n",
       "2   Struggling to log into the train service website   \n",
       "3  I tried accessing the train login page today b...   \n",
       "4  I tried accessing the train login page today b...   \n",
       "5  VPNs often cause issues with specific sites. T...   \n",
       "6  VPNs often cause issues with specific sites. T...   \n",
       "7  VPNs often cause issues with specific sites. T...   \n",
       "8  Sometimes browser cache or cookies cause loadi...   \n",
       "9  Sometimes browser cache or cookies cause loadi...   \n",
       "\n",
       "                     node_name  \n",
       "0   struggle_train_log_service  \n",
       "1              train_logistics  \n",
       "2                service_logix  \n",
       "3   secure_web_access_protocol  \n",
       "4          secure_access_suite  \n",
       "5    vpn_troubleshooting_guide  \n",
       "6    troubleshoot_task_manager  \n",
       "7                    solve_sit  \n",
       "8  cache_cookie_cause_resolver  \n",
       "9          cache_cookie_setter  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d2ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:50:19,757 - INFO - Successfully connected to Neo4j database.\n"
     ]
    }
   ],
   "source": [
    "# NEO4J_PASSWORD = \"cheesecake\"  # Replace with your actual Neo4j password\n",
    "# NEO4J_URI = \"bolt://localhost:7687\"  # Or your AuraDB URI\n",
    "# NEO4J_USER = \"neo4j\"\n",
    "\n",
    "# from graph_generator import Neo4jUploader  # Import if not already\n",
    "\n",
    "# uploader = Neo4jUploader(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a241eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Inferring solutions for symptoms: ['struggle_train_log_service', 'secure_web_access_protocol', 'vpn_troubleshooting_guide', 'cache_cookie_cause_resolver'] and known causes: ['train_logistics', 'secure_access_suite', 'solve_sit', 'cache_cookie_setter']\n",
      "INFO:root:Scores from symptoms path: {'vpn_troubleshooting_guide': 1.0}\n",
      "INFO:root:Scores from direct causes path (weighted): {}\n",
      "INFO:root:\n",
      "Combined & Ranked Recommended Treatments (Top 2):\n",
      "INFO:root:- Treatment: vpn_troubleshooting_guide, Combined Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "number_of_solutions_to_recommend = 2\n",
    "\n",
    "recommended_solutions = uploader.infer_solutions_from_dataframe(\n",
    "    inference_df, limit=number_of_solutions_to_recommend\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ddae453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vpn_troubleshooting_guide']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fce76988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 16:51:27,623 - INFO - Neo4j connection closed.\n"
     ]
    }
   ],
   "source": [
    "uploader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa6e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
